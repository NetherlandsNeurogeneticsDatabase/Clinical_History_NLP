{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Neurogenomics Database: Dotplot of entire dataset predictions\n",
    "Author: Nienke Mekkes <br>\n",
    "Date: 11-10-2022. <br>\n",
    "Correspond: n.j.mekkes@umcg.nl <br>\n",
    "\n",
    "## Script: Dotplot of entire dataset predictions\n",
    "Builds Dot Plots for each diagnosis category. <br>\n",
    "Why: to give an overview of what symptoms are frequently observed in different diagnosis groups\n",
    "\n",
    "### Input files:\n",
    "- prediction file (donors as row names, observations as columns)\n",
    "- General information: to assign metadata to donors (e.g. diagnosis, age)\n",
    "- Optional: attribute metadata to cluster observations\n",
    "- Optional: metadata to highlight expected findings in the plot\n",
    "\n",
    "- also needs scattermap.py, code to create the plot\n",
    "- also needs helper_functions, which contains code to run permutation test and how to select donors\n",
    "\n",
    "\n",
    "### Output:\n",
    "- dotplot, file with p values for permutation test\n",
    "\n",
    "\n",
    "\n",
    "#### Minimal requirements\n",
    "- to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this script works with a clinical trajectory dictionary pickle. this pickle can be a rules of thumb or a original pickle, and was generated by the script proces_predictions. This processing script removed short sentences etc. and the attributes that performed poorly. This processing script did not remove any donors. Donors that you wish to be excluded can be excluded in two ways: <br>\n",
    "1. in this script, manually. for example remove donors younger than 21. or donors with the NAD diagnosis, or reassign diagnosis (e.g. a SSA, CON donor NBB xxx needs to become HIV).\n",
    "2. with an input file, for example the general information that contains minimally one column with donorids, and one column that mentions which donors should have a changed diagnosis or should be excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_predictions = \"/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/final_predictions/ALL_clinical_trajectories_dictionary_2023-01-31.pkl\"\n",
    "path_to_predictions = \"/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/final_predictions/ALL_clinical_trajectories_dictionary_2023-08-14.pkl\"\n",
    "# path_to_predictions = \"/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/final_predictions/ALL_clinical_trajectories_dictionary_rules_of_thumb_visit_2023-07-11.pkl\"\n",
    "path_to_attribute_grouping = \"/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/input_data/sup3.xlsx\" ## for rules of thumb\n",
    "figure_folder = \"/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/final_predictions/figures/dotplots\"\n",
    "expected_attributes_path = \"/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/input_data/Clustercategories_and_expected_symptoms_03_may_2023.xlsx\"\n",
    "general_information = \"/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/input_data/General_information_11-08-2023.xlsx\"\n",
    "# path_clinical_diagnosis = '/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_diagnosis/output/selected_diagnoses_overview.xlsx'\n",
    "path_clinical_diagnosis = '/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_analysis/data/grud_clin_subset_overview_both.xlsx'\n",
    "# '/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_analysis/data/grud_clin_subset_overview_both.xlsx'\n",
    "# path_to_cleaned_training_data = \"/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/training_data/cleaned_training_data.pkl\"\n",
    "# path_to_diag = \"/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_diagnosis/clinical_diagnosis_02_may_2023.xlsx\"\n",
    "train_plot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import matplotlib\n",
    "import numpy as np; np.random.seed(0)\n",
    "from matplotlib import pyplot as plt \n",
    "import xlsxwriter\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import scattermap\n",
    "from scattermap import scattermap\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import statsmodels\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "import sys\n",
    "\n",
    "import scipy\n",
    "from helper_functions import permutation_of_individual_test, table_selector\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figure_folder):\n",
    "    print(f\"Creating output folder {figure_folder}\")\n",
    "    os.makedirs(figure_folder)\n",
    "else:\n",
    "    print(f\"Output folder {figure_folder} already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "We can make a dotplot on the full predicted set. However, a dotplot can also be made on the training data. The difference is that the training data contains more attributes (90 iso 80), and has a slightly different format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_plot == False:\n",
    "    with open(path_to_predictions,\"rb\") as file:\n",
    "        predictions_pickle = pickle.load(file)\n",
    "\n",
    "    d = []\n",
    "    for i,j in zip(predictions_pickle,predictions_pickle.values()):\n",
    "        k = pd.DataFrame.from_dict(j,orient=\"index\")\n",
    "        k[\"DonorID\"] = i\n",
    "        k['Age'] = k.index\n",
    "        d.append(k)\n",
    "\n",
    "    predictions_df =pd.concat(d, ignore_index=True)\n",
    "    display(predictions_df)\n",
    "    print(f\"there are {len(list(predictions_df['DonorID'].unique()))} unique donor IDs\")\n",
    "    print(predictions_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_plot == True:\n",
    "    with open(path_to_cleaned_training_data,\"rb\") as file:\n",
    "        predictions_pickle = pickle.load(file)\n",
    "        predictions_df = pd.DataFrame(predictions_pickle)\n",
    "\n",
    "    predictions_df = predictions_df.rename(columns={\"NBB_nr\": \"DonorID\"})\n",
    "    predictions_df.drop(['Year_Sentence_nr'], axis=1,inplace=True,  errors='ignore')\n",
    "    display(predictions_df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exclude/change donors for the paper, using general info\n",
    "- read in the general information\n",
    "- make a list of donors to remove\n",
    "- remove donors from our predictions\n",
    "- change column neuropathological diagnosis to the neuropathological diagnosis from the general information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_information_df = pd.read_excel(general_information, engine='openpyxl', sheet_name=\"Sheet1\")\n",
    "donors_to_remove = list(general_information_df[general_information_df['paper diagnosis']=='exclude'].DonorID)\n",
    "predictions_df = predictions_df[~predictions_df['DonorID'].isin(donors_to_remove)]\n",
    "print(f\"there are {len(list(predictions_df['DonorID'].unique()))} unique donor IDs\")\n",
    "print(len(donors_to_remove))\n",
    "predictions_df['neuropathological_diagnosis'] = predictions_df['DonorID'].map(general_information_df.set_index('DonorID')['paper diagnosis'])\n",
    "display(predictions_df.head())\n",
    "print(sorted(predictions_df['neuropathological_diagnosis'].unique()))\n",
    "print(f\"there are {len(list(predictions_df['DonorID'].unique()))} unique donor IDs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for easy manipulation later, make a list of the 80 (or 90 in case of training) signs and symptoms\n",
    "if train_plot == False:\n",
    "    non_attribute_columns = ['DonorID','Year','age_at_death','sex',\n",
    "                            'neuropathological_diagnosis','Age'] #'birthyear',,'death_year','year_before_death','sex',\n",
    "if train_plot == True:\n",
    "    non_attribute_columns = ['DonorID','neuropathological_diagnosis','Sentence'] #'birthyear',,'death_year','year_before_death','sex',\n",
    "attributes = [col for col in predictions_df.columns if col not in non_attribute_columns]\n",
    "# display(attributes)\n",
    "print(f\"there are {predictions_df.shape[0]} rows and {len(attributes)} attributes\")\n",
    "print(f\"there are {len(list(predictions_df['DonorID'].unique()))} unique donor IDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting future dotplot colors based on domain or grouping\n",
    "The attributes all belong to different 'domains' and subgroups. we color them based on these grouping. <br>\n",
    "\n",
    "We make two dictionaries with the attributes (values) grouped with their domains (keys). One with the finalised names, this dictionary will be used to plot the attribute names (e.g. no \"_\", with capitals). The other one has the 'pc_friendly' names, these are used for selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attribute_grouping = pd.read_excel(path_to_attribute_grouping, engine='openpyxl', index_col=[0])#,header=3, sheet_name='S3. 90 signs and symptoms')\n",
    "attribute_grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assign a custom color to each grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "group_dict_fancy = dict()\n",
    "color_dict_fancy = dict()\n",
    "count = 0\n",
    "\n",
    "colors = {'Aspecific symptoms':'#ce6dbd',#'Aspecific_symptoms'\n",
    "          'Autonomic dysfunction':'#b5cf6b',#'Autonomic_dysfunction'\n",
    "         'Cerebellar & vestibular system dysfunction': '#6b6ecf',#'Cerebral_vestibular_system_dysfunction'\n",
    "         'Changes in consciousness, awareness & orientation': '#d6616b',# Changes_in_consciousness_awareness_orientation\n",
    "         'Cognitive and memory impairment':'#e7ba52',#'cognitive_and_memory_impairment'\n",
    "          'Signs of (dis)inhibition':'#bd9e39',#'Disinhibition'\n",
    "          'Disturbances in mood & behaviour':'#ad494a',#Disturbances_in_mood_behaviour\n",
    "          'Extrapyramidal symptoms':'#9c9ede',#Extrapyramidal_signs_symptoms\n",
    "          'General decline':'#a55194',#\n",
    "          'Signs of impaired mobility':'#393b79',#Mobility_problems\n",
    "          'Motor deficits':'#5254a3',#Motor_deficit\n",
    "         'Other signs & symptoms of cortical dysfunction': '#e7cb94',#oth_signs_symptoms_cortical_dysfunction\n",
    "        'Other psychiatric signs & symptoms':  '#e7969c',#other_psychiatric_signs_symptoms\n",
    "          'Sensory deficits':'#8ca252'}#Sensory_deficits]\n",
    "\n",
    "\n",
    "    \n",
    "for attr, group in zip(attribute_grouping[\"AttributeUpdated\"], attribute_grouping[\"Grouping\"]):\n",
    "    if group not in group_dict_fancy:\n",
    "#         print(f\"{attr} belonging to {group}, grouping is new\")\n",
    "        if not isinstance(group, float):\n",
    "            group_dict_fancy[group] = []\n",
    "            color_dict_fancy[group] = colors[group]\n",
    "#             print(colors[group])\n",
    "#             print(color_dict_fancy)\n",
    "            group_dict_fancy[group].append(attr)\n",
    "            count +=1\n",
    "    else:\n",
    "        group_dict_fancy[group].append(attr)\n",
    "\n",
    "\n",
    "\n",
    "# Sort the lists within the dictionary\n",
    "group_dict_fancy = {k: sorted(v) for k, v in group_dict_fancy.items()}\n",
    "\n",
    "print(group_dict_fancy, '\\n')\n",
    "print(color_dict_fancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define order of displaying groupings/domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_order = ['Aspecific symptoms',\n",
    "                'General decline',\n",
    "                'Extrapyramidal symptoms',\n",
    "                'Cerebellar & vestibular system dysfunction',\n",
    "                'Motor deficits',\n",
    "                'Signs of impaired mobility',\n",
    "                'Autonomic dysfunction',\n",
    "                'Sensory deficits',\n",
    "                'Other signs & symptoms of cortical dysfunction',\n",
    "                'Cognitive and memory impairment',\n",
    "                'Signs of (dis)inhibition',\n",
    "                'Other psychiatric signs & symptoms',\n",
    "                'Changes in consciousness, awareness & orientation',\n",
    "                'Disturbances in mood & behaviour',\n",
    "               ]\n",
    "\n",
    "new_order_fancy = []\n",
    "for x in group_order:\n",
    "    # print(x)\n",
    "    group_fancy = group_dict_fancy[x]\n",
    "    for attr in group_fancy:\n",
    "        new_order_fancy.append(attr)\n",
    "        # print(attr)\n",
    "new_order_fancy.reverse()\n",
    "print(new_order_fancy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove 10 poorly performing attributes & synonyms\n",
    "while the 10 signs and symptoms are not present in the prediction, they are still present in the dictionaries created above. We remove them here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_plot == False:\n",
    "    # new_order_fancy.remove('Unspecified disturbed gait patterns')\n",
    "    # new_order_fancy.remove('Loss of sympathy / empathy')\n",
    "    # new_order_fancy.remove('Headturning sign')\n",
    "    # new_order_fancy.remove('Impaired comprehension')\n",
    "    # new_order_fancy.remove('Changed behavior/personality')\n",
    "    # new_order_fancy.remove('Frontal release signs')\n",
    "    new_order_fancy.remove('Disturbed gait')\n",
    "    new_order_fancy.remove('Loss of sympathy / empathy')\n",
    "    new_order_fancy.remove('Headturning sign')\n",
    "    new_order_fancy.remove('Limited language comprehension')\n",
    "    new_order_fancy.remove('Changed behavior/personality')\n",
    "    new_order_fancy.remove('Frontal release signs')\n",
    "    # new_order_fancy\n",
    "\n",
    "    # remove 4 synonyms\n",
    "    # new_order_fancy.remove('Ataxia')\n",
    "    # new_order_fancy.remove('Lack of initiative')\n",
    "    # new_order_fancy.remove('Lack of planning / organization / overview')\n",
    "    # new_order_fancy.remove('Cognitive decline')\n",
    "len(new_order_fancy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want to display the attributes using the official names from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_names = {}\n",
    "\n",
    "for attr, real_name in zip(attribute_grouping[\"AttributeUpdated\"], attribute_grouping[\"ITname\"]):\n",
    "    if not isinstance(real_name, float):\n",
    "        correct_names[real_name] = attr\n",
    "# correct_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = predictions_df.rename(correct_names,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### change the attribute order to the one we want to display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information_from_symptoms_df = predictions_df[non_attribute_columns]\n",
    "attribute_columns_to_sort = predictions_df.loc[:,[i for i in list(predictions_df.columns) if i not in non_attribute_columns]]\n",
    "attribute_columns_to_sort = attribute_columns_to_sort[new_order_fancy]\n",
    "          \n",
    "              \n",
    "# updated symptoms_df, now with the right columns order (e.g. start with communication problems)\n",
    "predictions_df = pd.concat([information_from_symptoms_df, attribute_columns_to_sort], axis=1)\n",
    "display(predictions_df)\n",
    "predictions_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONLY FOR ANALYSIS OF CLINICAL DIAGNOSIS!\n",
    "- this selects a specififc subset of diagnoses and donors\n",
    "- these are: wantedx = ['CON','AD', 'PD', 'VD', 'FTD', 'DLB', 'AD-DLB', 'ATAXIA', 'MND', 'PSP', 'MS', 'MSA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = False\n",
    "# cd = False\n",
    "if cd == True:\n",
    "    # grouper = 'donorcount'\n",
    "    cd_df = pd.read_excel(path_clinical_diagnosis, engine='openpyxl')\n",
    "    # display(cd_df.head())\n",
    "    # display(predictions_df)\n",
    "    merged_df = predictions_df.merge(cd_df[['DonorID', 'diagnosis_info','pred_info','neuropathological_diagnosis']], on='DonorID', how='inner')\n",
    "    \n",
    "#     ordered_diagnoses = ['CON','AD', 'PD', 'VD', 'FTD', 'DLB', 'AD-DLB', 'ATAXIA', 'MND', 'PSP', 'MS', 'MSA']\n",
    "#     ordered_diagnoses = ['CON_coherent','CON_non-coherent','AD_coherent','AD_non-coherent', 'PD_coherent','PD_non-coherent',\n",
    "#                          'VD_coherent','VD_non-coherent', 'FTD_coherent','FTD_non-coherent', 'DLB_coherent','DLB_non-coherent',\n",
    "#                          'AD-DLB_coherent','AD-DLB_non-coherent', 'ATAXIA_coherent','ATAXIA_non-coherent',\n",
    "#                          'PSP_coherent','PSP_non-coherent', # 'MND_coherent','MND_non-coherent',\n",
    "#                          'MS_coherent', 'MS_non-coherent', 'MSA_coherent','MSA_non-coherent']\n",
    "    grouper = 'neuropathological_diagnosis'\n",
    "    merged_df.rename(columns={'neuropathological_diagnosis_y': 'neuropathological_diagnosis'}, inplace=True)\n",
    "    merged_df.drop(['Year','age_at_death','sex','Age','neuropathological_diagnosis_x'], axis=1,inplace=True, errors='ignore') #\n",
    "\n",
    "    def determine_judge(row):\n",
    "        if row['pred_info'] == 'non-coherent' and row['diagnosis_info'] == 'non-coherent':\n",
    "            return 'non-coherent'\n",
    "        elif row['diagnosis_info'] == 'non-coherent' and row['pred_info'] == 'ambiguous':\n",
    "            return 'non-coherent'\n",
    "        else:\n",
    "            return 'coherent'\n",
    "\n",
    "    # Apply the function to create the 'judge' column\n",
    "    merged_df['judge'] = merged_df.apply(determine_judge, axis=1)   \n",
    "    display(merged_df['diagnosis_info'].value_counts())\n",
    "    display(merged_df['pred_info'].value_counts())\n",
    "    display(merged_df['judge'].value_counts())\n",
    "    # merged_df['judge'] = \n",
    "    # display(merged_df.head())\n",
    "\n",
    "#     #### IMPORTANT, for simplicity change ambiguous to coherent!!!!!!!!\n",
    "    # merged_df['judge'] = merged_df['diagnosis_info']\n",
    "    # merged_df['judge'] = merged_df['judge'].replace('ambiguous', 'coherent')\n",
    "    \n",
    "#     ###### or ignore ambiguous\n",
    "      # merged_df['judge'] = merged_df['diagnosis_info']\n",
    "#     merged_df = merged_df[merged_df['judge'] != 'ambiguous']\n",
    "#     # display(merged_df)\n",
    "    \n",
    "    flattened_t1 = merged_df.groupby(['DonorID','neuropathological_diagnosis','judge'], as_index=False).sum()\n",
    "    flattened_t1_forp = flattened_t1.copy()\n",
    "    flattened_t1_forp['new_neuropathological_diagnosis'] = flattened_t1_forp['neuropathological_diagnosis'] + '_' + flattened_t1_forp['judge']\n",
    "    flattened_t1_forp.drop(columns=['neuropathological_diagnosis', 'judge'], inplace=True)\n",
    "    flattened_t1_forp.rename(columns={'new_neuropathological_diagnosis': 'neuropathological_diagnosis'}, inplace=True)\n",
    "    columns = flattened_t1_forp.columns.tolist()\n",
    "    columns.insert(1, columns.pop())\n",
    "    flattened_t1_forp = flattened_t1_forp[columns]\n",
    "    flattened = merged_df.groupby(['DonorID','neuropathological_diagnosis','judge'], as_index=False).sum()\n",
    "    flattened_forp = flattened.copy()\n",
    "    flattened_forp['new_neuropathological_diagnosis'] = flattened_forp['neuropathological_diagnosis'] + '_' + flattened_forp['judge']\n",
    "    flattened_forp.drop(columns=['neuropathological_diagnosis', 'judge'], inplace=True)\n",
    "    flattened_forp.rename(columns={'new_neuropathological_diagnosis': 'neuropathological_diagnosis'}, inplace=True)\n",
    "    columns = flattened_forp.columns.tolist()\n",
    "    columns.insert(1, columns.pop())\n",
    "    flattened_forp = flattened_forp[columns]\n",
    "    ordered_diagnoses = flattened_forp['neuropathological_diagnosis'].unique()\n",
    "\n",
    "display(flattened_forp['neuropathological_diagnosis'].value_counts())\n",
    "display(flattened_forp.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### intermezzo: alyses clusters\n",
    "comment out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## for MS analyses we have to load the MS cluster IDs\n",
    "# alyse_df = selected_diagnoses.copy()\n",
    "# alyse_clusters = \"/home/jupyter-n.mekkes@gmail.com-f6d87/ext_n_mekkes_gmail_com/clinical_history/input_data/alyse_ms_clusters.xlsx\"\n",
    "# alyse_clusters = pd.read_excel(alyse_clusters)\n",
    "\n",
    "# ## this is the order we want to display\n",
    "# ordered_diagnoses =  ['CON','Cluster1','Cluster2','Cluster3','Cluster4']\n",
    "\n",
    "# ## we add the cluster ID to our predictions and keep only these donors and the controls\n",
    "# alyse_df['alyse_clusters'] = alyse_df['DonorID'].map(alyse_clusters.set_index('DonorID')['Cluster'])\n",
    "# alyse_df.alyse_clusters.fillna(alyse_df.neuropathological_diagnosis, inplace=True)\n",
    "# alyse_df= alyse_df[alyse_df['alyse_clusters'].isin(ordered_diagnoses)]\n",
    "# alyse_df['neuropathological_diagnosis'] = alyse_df['alyse_clusters']\n",
    "# alyse_df = alyse_df.drop('alyse_clusters',axis=1)\n",
    "# display(alyse_df['neuropathological_diagnosis'].value_counts())\n",
    "# selected_diagnoses = alyse_df.copy()\n",
    "# display(alyse_df)\n",
    "\n",
    "#### for ms analysis, the background is all donors that are NOT MS. to do this, select table1_ms. for standard uses, select table1 as background\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (FOR ALL DONORS) Selecting groups of diagnoses to display in dotplot\n",
    "We do not want to print all hundreds of diagnoses, but make a selection. here we use a dictionary approach to select diagnoses and give them an appropriate abbreviation in one go. The function also returns a default order of diagnoses. for example, all FTD subtypes are grouped into 'FTD'. <br>\n",
    "\n",
    "#### selecting a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd = False\n",
    "if cd == False:\n",
    "    table_of_choice = 'table1_p' #fig 4a table3_with_con_p #table2_p #fig 3a table1_P fig sup 5a:table2_p\n",
    "    selected_diagnoses,ordered_diagnoses = table_selector(table_of_choice, predictions_df)\n",
    "    print('After selecting for {}, we have {} donors'.format(selected_diagnoses['neuropathological_diagnosis'].unique(),\n",
    "                                                                                        selected_diagnoses['DonorID'].nunique()) )\n",
    "    display(selected_diagnoses[selected_diagnoses['neuropathological_diagnosis']=='AD'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selecting background\n",
    "For the permutation analysis, we want to compare a finding within a diagnosis group to a random background. The default random background is formed by the diagnoses as defined here in 'table 1'. For example, 90% of the 500 donors with AD experience symptom x. If we randomly select 500 donors from the random background, what is their observation? repeat this random sampling n times.\n",
    "\n",
    "### preprocessing\n",
    "- We do not need all information columns, clean them up\n",
    "- flatten the data: we sum the nr of observations per donor. \n",
    "- create an overview of the number of observations within each diagnosis group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd = False\n",
    "if cd == False:\n",
    "    table1, _ = table_selector('table1_p', predictions_df)\n",
    "    print('After selecting for {}, we have {} donors'.format(table1['neuropathological_diagnosis'].unique(),\n",
    "                                                                                        table1['DonorID'].nunique()) )\n",
    "    grouper = 'neuropathological_diagnosis'\n",
    "\n",
    "    if train_plot == False:\n",
    "        table1.drop(['Year','age_at_death','sex','Age'], axis=1,inplace=True, errors='ignore') #,anti_grouper\n",
    "        selected_diagnoses.drop(['Year','age_at_death','sex','Age'], axis=1,inplace=True,  errors='ignore') #,anti_grouper\n",
    "    if train_plot == True:\n",
    "        table1.drop(['Sentence'], axis=1,inplace=True, errors='ignore') ## for training data\n",
    "        selected_diagnoses.drop(['Sentence'], axis=1,inplace=True,  errors='ignore') ## for training data\n",
    "\n",
    "    flattened_t1 = table1.groupby(['DonorID',grouper], as_index=False).sum()\n",
    "    flattened = selected_diagnoses.groupby(['DonorID',grouper], as_index=False).sum()\n",
    "\n",
    "    selected_donorcountpredict = table1['DonorID'].nunique()\n",
    "    disease_counts = pd.DataFrame(flattened[grouper].value_counts())\n",
    "    disease_counts = disease_counts.reindex(ordered_diagnoses)\n",
    "    display(disease_counts)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from here, code works for all sets. calculate proportions\n",
    "goal: if 500 donors have AD, and 250 of those donors experience symptom x, then the proportion of symptom x equals 0.5\n",
    "To calculate this we perform the following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## endgoal: divide total nr of donors in a diagnosis group by the nr of donors suffering from attribute x\n",
    "## step 1: make boolean df: a donor either has a attribute or not, i dont care about how often.\n",
    "## by setting it to 1, we can sum and see how many donors have this attribute\n",
    "# display(group_ready.head(5))\n",
    "# cd = False\n",
    "if cd == False:\n",
    "    group_ready = flattened.copy()\n",
    "    group_ready.loc[:,[i for i in new_order_fancy]] = group_ready.loc[:,[i for i in new_order_fancy]].apply(lambda x: [y if y <= 1 else 1 for y in x])\n",
    "    grouped_df = group_ready.groupby([grouper])\n",
    "    # Calculating the percentage for each column in each group\n",
    "    proportion_df = grouped_df.apply(lambda x: pd.Series({\n",
    "        'total': len(x),\n",
    "        **{column: x[column].mean() * 300 for column in new_order_fancy}\n",
    "    }))\n",
    "\n",
    "if cd == True:\n",
    "    group_ready = flattened_forp.copy()\n",
    "    group_ready.loc[:,[i for i in new_order_fancy]] = group_ready.loc[:,[i for i in new_order_fancy]].apply(lambda x: [y if y <= 1 else 1 for y in x])\n",
    "\n",
    "    grouped_df = group_ready.groupby(['neuropathological_diagnosis'])\n",
    "    # grouped_df = group_ready.groupby(['neuropathological_diagnosis', 'diagnosis_info'])\n",
    "    proportion_df = grouped_df.apply(lambda x: pd.Series({\n",
    "        'donorcount': len(x),\n",
    "        **{column: x[column].mean() * 300 for column in new_order_fancy}\n",
    "    }))\n",
    "    proportion_df['total'] = proportion_df.groupby(['neuropathological_diagnosis']).transform('sum')['donorcount']\n",
    "\n",
    "\n",
    "proportion_df = proportion_df.reindex(ordered_diagnoses, level='neuropathological_diagnosis')\n",
    "# display(proportion_df)\n",
    "if cd == True:\n",
    "    disease_counts = pd.DataFrame(proportion_df['donorcount']) ## if you have cd\n",
    "    disease_counts.rename(columns={'donorcount': 'neuropathological_diagnosis'}, inplace=True)\n",
    "    disease_counts.index.name = None\n",
    "proportion_df = proportion_df.drop(['total'],axis=1)\n",
    "if cd == True:\n",
    "    proportion_df = proportion_df.drop(['donorcount'],axis=1) ## if you have cd\n",
    "    proportion_df.to_excel(f\"{figure_folder}/clindiags/percentages.xlsx\") ## if you have cd\n",
    "if cd == False:\n",
    "    proportion_df.to_excel(f\"{figure_folder}/{table_of_choice}/percentages.xlsx\")\n",
    "\n",
    "# display(disease_counts_forp)\n",
    "display(disease_counts)\n",
    "## results:\n",
    "## - flattened_t1_forp\n",
    "## - flattened_forp\n",
    "## grouper\n",
    "## ordered_diagnoses\n",
    "## disease_counts\n",
    "## proportion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MS intermezzo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diag = 'MS'\n",
    "\n",
    "# # Filter by rows with the diagnosis and select columns with values greater than 10\n",
    "# symptoms = proportion_df.loc[diag] \n",
    "# symptoms = list(symptoms[symptoms >= 25].index)\n",
    "# # symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from scipy.stats import zscore\n",
    "\n",
    "# flattened_ms = flattened[flattened['neuropathological_diagnosis']==diag]\n",
    "# flattened_ms = flattened_ms.drop('neuropathological_diagnosis',axis=1)\n",
    "# flattened_ms.set_index('DonorID',drop=True,inplace=True)\n",
    "\n",
    "# # check which columns have all zeros\n",
    "# zeros = (flattened_ms == 0).all(axis=0)\n",
    "\n",
    "# # drop the columns with all zeros\n",
    "# flattened_ms = flattened_ms.loc[:, ~zeros]\n",
    "\n",
    "# # calculate the total number of observations for each donor\n",
    "# totals = flattened_ms.sum(axis=1)\n",
    "# coltotals = flattened_ms.sum(axis=0)\n",
    "# # divide each row by its corresponding total\n",
    "# flattened_ms = flattened_ms.div(totals, axis=0)\n",
    "# # flattened_ms = flattened_ms.div(coltotals, axis=1)\n",
    "# # flattened_ms = flattened_ms.apply(zscore, axis=1)\n",
    "\n",
    "# flattened_ms.fillna(0, inplace=True)\n",
    "# # display(flattened_ms.sort_values('Fasciculations')['Fasciculations'])\n",
    "# display(flattened_ms['Dementia'].describe())\n",
    "# # display(flattened_ms['Fasciculations'].describe())\n",
    "# # display(totals)\n",
    "# # display(flattened_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from scipy.cluster import hierarchy\n",
    "\n",
    "\n",
    "# MS_interesting_dict = {}\n",
    "# MS_interesting_dict['expob'] = ['Decreased (fine) motor skills','Fatigue','Spasticity','Declined / deteriorated health','Urinary incontinence','Muscular weakness']\n",
    "# MS_interesting_dict['expnob'] = ['Concentration problems','Dementia','Depressed mood']\n",
    "# MS_interesting_dict['nexpob'] = ['Vertigo','Headache / migraine','Nystagmus','Help in ADL','Balance problems','Swallowing problems / dysphagia',\n",
    "#                     'Dysarthria','Constipation','Urinary problems (other)','Visual problems','Negative sensory symptoms','Positive sensory symptoms',\n",
    "#                     'Hyperreflexia and other pathological reflexes','Loss of coordination','Mobility problems'                   \n",
    "#                    ]\n",
    "\n",
    "\n",
    "# # # Create a list of all the interesting symptom names\n",
    "# interesting_symptoms = [symptom for symptom_list in MS_interesting_dict.values() for symptom in symptom_list]\n",
    "\n",
    "# # # Select the interesting columns from the DataFrame\n",
    "# flattened_ms = flattened_ms.loc[:, interesting_symptoms]\n",
    "# # flattened_ms = flattened_ms.loc[:, symptoms]\n",
    "\n",
    "# # Set the figure size\n",
    "# plt.figure(figsize=(30, 30))\n",
    "# sns.set(font_scale=1.5)\n",
    "\n",
    "\n",
    "# corr_matrix = flattened_ms.corr()\n",
    "# sns.heatmap(corr_matrix, cmap='coolwarm', annot=False, fmt='.2f',\n",
    "#             xticklabels=corr_matrix.columns.values, yticklabels=corr_matrix.columns.values,\n",
    "#             # annot_kws={\"size\": 5}\n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # plt.figure(figsize=(10, 12))\n",
    "# sns.set(font_scale=0.8)\n",
    "\n",
    "# sns.clustermap(corr_matrix, method='average', metric='cosine',#,method='ward',metric='euclidean',\n",
    "#                cmap='coolwarm',\n",
    "#                cbar_pos=(1.05, 0.2, 0.05, 0.6),\n",
    "#                figsize=(10, 10)\n",
    "              \n",
    "#               )\n",
    "# plt.savefig(f\"/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/final_predictions_extrasyny/figures/cooccurence/{diag}_cooc.png\",bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we also calculate the mean number of observations\n",
    "Goal: if 250 donors with AD observe symptom x 2 times, and 250 never observe it, than the mean equals 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cd == False:\n",
    "    general_mean_multi = flattened.groupby(grouper).mean()\n",
    "    general_mean_multi = general_mean_multi.reindex(ordered_diagnoses)\n",
    "\n",
    "if cd == True:\n",
    "    general_mean_multi = flattened_forp.groupby(['neuropathological_diagnosis']).mean()\n",
    "    general_mean_multi = general_mean_multi.reindex(ordered_diagnoses, level='neuropathological_diagnosis')\n",
    "    display(general_mean_multi.head())\n",
    "    print(general_mean_multi.max())\n",
    "    # general_mean_multi_forp = general_mean_multi.copy()\n",
    "    # general_mean_multi_forp.reset_index(inplace=True)\n",
    "    # general_mean_multi_forp['combined_index'] = general_mean_multi_forp['neuropathological_diagnosis'] + '_' + general_mean_multi_forp['diagnosis_info']\n",
    "    # general_mean_multi_forp.set_index('combined_index', inplace=True)\n",
    "    # general_mean_multi_forp.drop(columns=['neuropathological_diagnosis', 'diagnosis_info'], inplace=True)\n",
    "    # general_mean_multi_forp = general_mean_multi_forp.rename_axis('neuropathological_diagnosis')\n",
    "    # ordered_diagnoses = disease_counts_forp.index\n",
    "    # display(general_mean_multi_forp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation testing\n",
    "Only run this script once, takes a lot of time if you dont have resources. can be skipped if you dont need significane, then do not plot significance in the visualization or you will get an error. Can also be faster if you run less permutations. standard set to 100.000, which is very high! <br>\n",
    "\n",
    "main concept <br>\n",
    "- loop over each diagnosis\n",
    "- how many donors have diagnosis x?\n",
    "- run permutation test, which needs:\n",
    "    - the name of the current diagnosis\n",
    "    - the flattened dataframe (for every donor, summed observations)\n",
    "    - the mean dataframe (for every diagnosis, how many mean observations)\n",
    "    - the number of donors\n",
    "    - the background flattened dataframe (for every donor, summed observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_plot == False:\n",
    "    if cd == False:\n",
    "        table_folder = \"{}/{}\".format(figure_folder,table_of_choice)\n",
    "    elif cd == True:\n",
    "        table_folder = \"{}/{}\".format(figure_folder,'clindiags')\n",
    "if train_plot == True:\n",
    "    table_folder = \"{}/{}_training\".format(figure_folder,table_of_choice)\n",
    "print(table_folder)\n",
    "\n",
    "if not os.path.exists(table_folder):\n",
    "    print('Creating output folder....')\n",
    "    os.makedirs(table_folder)\n",
    "    \n",
    "save_permutation = \"{}/p_values.xlsx\".format(table_folder)\n",
    "save_permutation_cor = \"{}/cor_p_values.xlsx\".format(table_folder)\n",
    "print(save_permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def identify_diagnosis_Pvalues(flattened, general_mean_multi, disease_counts, flattened_t1):\n",
    "\n",
    "    ##Function that is a wrapper around permutation_of_individual_test and saves all P-values\n",
    "    ##Make a diagnosis dictionary with a attrobite dictionary that contains all the P-values \n",
    "    p_values_diagnosis_dictionary = {} \n",
    "    perms = 10000\n",
    "    nr = 1\n",
    "    # for d in ordered_diagnoses:\n",
    "    for d in disease_counts.index:\n",
    "        ##Print messages\n",
    "        message = '--------------------------------------- \\n \\\n",
    "                   Working on {primary_diagnosis}, {v} out of {len_pd}'.format(primary_diagnosis=d,v=nr,len_pd=len(disease_counts.index))\n",
    "        print(message)\n",
    "        nr = nr + 1\n",
    "        # display(d)\n",
    "        nr_donors_with_d = disease_counts.loc[d][grouper]\n",
    "        if math.isnan(nr_donors_with_d):\n",
    "            print('no instances!')\n",
    "        else:\n",
    "            nr_donors_with_d = int(nr_donors_with_d)\n",
    "            print('diagnosis affects {} donors.'.format(nr_donors_with_d))\n",
    "\n",
    "            ## multiproc\n",
    "            p_values_attribute_dictionary = {} \n",
    "            iterable = [attribute_nr for attribute_nr in range(2,flattened.shape[1])]\n",
    "            # print(iterable)\n",
    "            pool = multiprocessing.Pool(multiprocessing.cpu_count()-1)\n",
    "            # display(disease_counts)\n",
    "            # display(flattened)\n",
    "            # display(general_mean_multi)\n",
    "            func = partial(permutation_of_individual_test, d, flattened, general_mean_multi, nr_donors_with_d,perms,flattened_t1,grouper)\n",
    "            res = pool.map(func, iterable)\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "\n",
    "            p_values_diagnosis_dictionary[d] = res\n",
    "        \n",
    "#         ## without multiproc\n",
    "#         p_values_attribute_dictionary = {} \n",
    "\n",
    "#         for attribute_nr in range(2,flattened.shape[1]): #range(2,6):\n",
    "#             message2 = 'Working on attribute {nr}: {attribute}'.format(nr=attribute_nr-2,\n",
    "#                                                                        attribute=flattened.columns[attribute_nr])\n",
    "#             print(message2)\n",
    "#             p_value = permutation_of_individual_test(d,\n",
    "#                                                      flattened,\n",
    "#                                                      general_mean_multi,\n",
    "#                                                      nr_donors_with_d,\n",
    "#                                                      flattened_t1,\n",
    "#                                                      attribute_nr,\n",
    "#                                                      m_or_m='mean')#, donor_diagnosis_list)\n",
    "#             p_values_attribute_dictionary[attribute_nr] = p_value\n",
    "\n",
    "#         p_values_diagnosis_dictionary[d] = p_values_attribute_dictionary\n",
    "    \n",
    "    return p_values_diagnosis_dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### running the permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if cd == True:\n",
    "#     flattend_forp = flattened.copy()\n",
    "#     flattend_forp['new_neuropathological_diagnosis'] = flattend_forp['neuropathological_diagnosis'] + '_' + flattend_forp['diagnosis_info']\n",
    "#     flattend_forp.drop(columns=['neuropathological_diagnosis', 'diagnosis_info'], inplace=True)\n",
    "#     flattend_forp.rename(columns={'new_neuropathological_diagnosis': 'neuropathological_diagnosis'}, inplace=True)\n",
    "#     columns = flattend_forp.columns.tolist()\n",
    "#     columns.insert(1, columns.pop())\n",
    "#     flattend_forp = flattend_forp[columns]\n",
    "#     flattened_t1_forp = flattened_t1.copy()\n",
    "#     flattened_t1_forp['new_neuropathological_diagnosis'] = flattened_t1_forp['neuropathological_diagnosis'] + '_' + flattened_t1_forp['diagnosis_info']\n",
    "#     flattened_t1_forp.drop(columns=['neuropathological_diagnosis', 'diagnosis_info'], inplace=True)\n",
    "#     flattened_t1_forp.rename(columns={'new_neuropathological_diagnosis': 'neuropathological_diagnosis'}, inplace=True)\n",
    "#     columns = flattened_t1_forp.columns.tolist()\n",
    "#     columns.insert(1, columns.pop())\n",
    "#     flattened_t1_forp = flattened_t1_forp[columns]\n",
    "#     display(ordered_diagnoses)\n",
    "#     # general_mean_multi_forp.index.name = None\n",
    "#     # display(flattend_forp.head())\n",
    "#     # display(flattened_t1_forp.head())\n",
    "# display(disease_counts.head())\n",
    "#     # display(general_mean_multi_forp.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cd == True:\n",
    "    Pvalues_dict = identify_diagnosis_Pvalues(flattened_forp, general_mean_multi, disease_counts, flattened_t1_forp)\n",
    "elif cd == False:\n",
    "    Pvalues_dict = identify_diagnosis_Pvalues(flattened, general_mean_multi, disease_counts, flattened_t1)    \n",
    "prelim = pd.DataFrame(Pvalues_dict)\n",
    "Pvalues_dataframe = prelim.T\n",
    "Pvalues_dataframe.columns = list(general_mean_multi.columns)\n",
    "display(Pvalues_dataframe)\n",
    "\n",
    "writer = pd.ExcelWriter(save_permutation, engine='xlsxwriter')\n",
    "Pvalues_dataframe.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading stored permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pvalues_dataframe = pd.read_excel(save_permutation, engine='openpyxl', index_col=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pvalues_dataframe=Pvalues_dataframe.reindex(ordered_diagnoses)\n",
    "display(Pvalues_dataframe)\n",
    "print(Pvalues_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pvalues_dataframe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### correct for multiple testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FDR_conversion(Pvalues_dataframe):\n",
    "    ##Function that converts a P-value dataframe to FDR dataframe \n",
    "    import statsmodels.stats.multitest as smt\n",
    "    \n",
    "    Pvalues_list = [] \n",
    "    for index_value in Pvalues_dataframe.index:\n",
    "        # print(index_value)\n",
    "        Pvalues_list+= Pvalues_dataframe.loc[index_value,:].values.tolist()\n",
    "    # print(Pvalues_list)\n",
    "\n",
    "    FDRvalues_list = smt.multipletests(Pvalues_list, method='fdr_bh', is_sorted= False)[1]    \n",
    "    FDRvalues_array = np.array(FDRvalues_list) \n",
    "    FDRvalues_array = np.reshape(FDRvalues_array, Pvalues_dataframe.shape)\n",
    "    FDR_df = pd.DataFrame(FDRvalues_array, columns= Pvalues_dataframe.columns, index= Pvalues_dataframe.index)\n",
    "    \n",
    "    return FDR_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_df = FDR_conversion(Pvalues_dataframe)\n",
    "FDR_Cutoff = 0.1\n",
    "significance_boolean = (FDR_df < FDR_Cutoff) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(significance_boolean)\n",
    "\n",
    "writer = pd.ExcelWriter(save_permutation_cor, engine='xlsxwriter')\n",
    "FDR_df.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our colleagues from the NHB wrote down their expectations for each attribute and diagnosis. we plot these as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Add expected attributes per diagnosis - for plotting \n",
    "expected_attributes_df = pd.read_excel(expected_attributes_path, index_col=0,sheet_name='Updated version 20042022')\n",
    "\n",
    "expected_attributes_df.fillna(0,inplace=True)\n",
    "expected_attributes_df = expected_attributes_df.astype('int')\n",
    "print(pd.unique(expected_attributes_df.values.ravel('K')))\n",
    "expected_attributes_df = expected_attributes_df.rename(columns={'Executive_dysfunction': 'Executive_function_disorder',\n",
    "                                                                'Lack_of_planning_organisation':'Lack_of_planning_organis_overv',\n",
    "                                                               'Unspecified_disturbed_gait_patterns': 'Unspecified_disturbed_gait_patt'})\n",
    "expected_attributes_df = expected_attributes_df.rename(columns={\"Fatique\": \"Fatigue\"})\n",
    "expected_attributes_df= expected_attributes_df.rename(correct_names,axis=1)\n",
    "expected_attributes_df = expected_attributes_df.reindex(ordered_diagnoses)\n",
    "# display(expected_attributes_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def synonym_merger_new(df, how=None):\n",
    "#     if how == 'sum':\n",
    "#         df[\"Loss of coordination\"] = df[[\"Ataxia\", \"Loss of coordination\"]].sum(axis=1)\n",
    "#         # df[\"Apathy / inertia\"] = df[[\"Apathy / inertia\", \"Lack of initiative\"]].sum(axis=1)\n",
    "#         # df[\"Dementia\"] = df[[\"Dementia\", \"Cognitive decline\"]].sum(axis=1)\n",
    "#         # df[\"Executive function disorders\"] = df[[\"Executive function disorders\", \"Lack of planning / organization / overview\"]].sum(axis=1)\n",
    "#         # df[\"Memory_impairment\"] = df[[\"Memory_impairment\", \"Amnesia\",\"Forgetfulness\",\"Imprinting_disturbances\"]].sum(axis=1)\n",
    "#         # df[\"Disorientation\"] = df[[\"Disorientation\", \"Wandering\"]].sum(axis=1)\n",
    "#     elif how == 'max':\n",
    "#         df[\"Loss of coordination\"] = df[[\"Ataxia\", \"Loss of coordination\"]].max(axis=1)\n",
    "#         # df[\"Apathy / inertia\"] = df[[\"Apathy / inertia\", \"Lack of initiative\"]].max(axis=1)\n",
    "#         # df[\"Dementia\"] = df[[\"Dementia\", \"Cognitive decline\"]].max(axis=1)\n",
    "#         # df[\"Executive function disorders\"] = df[[\"Executive function disorders\", \"Lack of planning / organization / overview\"]].max(axis=1)\n",
    "#         # df[\"Memory impairment\"] = df[[\"Memory impairment\", \"Amnesia\",\"Forgetfulness\",\"Imprinting disturbances\"]].max(axis=1)\n",
    "#         # df[\"Disorientation\"] = df[[\"Disorientation\", \"Wandering\"]].max(axis=1)\n",
    "#     df.drop(['Ataxia',], axis=1,inplace=True)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def synonym_merger(df, how=None):\n",
    "#     if how == 'sum':\n",
    "#         df[\"Loss of coordination\"] = df[[\"Ataxia\", \"Loss of coordination\"]].sum(axis=1)\n",
    "#         df[\"Apathy / inertia\"] = df[[\"Apathy / inertia\", \"Lack of initiative\"]].sum(axis=1)\n",
    "#         df[\"Dementia\"] = df[[\"Dementia\", \"Cognitive decline\"]].sum(axis=1)\n",
    "#         df[\"Executive function disorders\"] = df[[\"Executive function disorders\", \"Lack of planning / organization / overview\"]].sum(axis=1)\n",
    "#     elif how == 'max':\n",
    "#         df[\"Loss of coordination\"] = df[[\"Ataxia\", \"Loss of coordination\"]].max(axis=1)\n",
    "#         df[\"Apathy / inertia\"] = df[[\"Apathy / inertia\", \"Lack of initiative\"]].max(axis=1)\n",
    "#         df[\"Dementia\"] = df[[\"Dementia\", \"Cognitive decline\"]].max(axis=1)\n",
    "#         df[\"Executive function disorders\"] = df[[\"Executive function disorders\", \"Lack of planning / organization / overview\"]].max(axis=1)\n",
    "#     df.drop(['Lack of initiative','Cognitive decline','Ataxia',\"Lack of planning / organization / overview\"], axis=1,inplace=True)\n",
    "#     return df\n",
    "\n",
    "# if train_plot == False:\n",
    "#     expected_attributes_df = synonym_merger_new(expected_attributes_df, how='max') ## turn off ## for training data\n",
    "expected_attributes_df = expected_attributes_df[list(general_mean_multi.columns)]\n",
    "expected_attributes_df = expected_attributes_df.fillna(0)\n",
    "display(expected_attributes_df)\n",
    "print(expected_attributes_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# significance_boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe to store the results\n",
    "results = pd.DataFrame(index=expected_attributes_df.index, columns=['expected_and_observed','expected_but_not_observed', 'not_expected_but_observed'])\n",
    "\n",
    "# loop over each diagnosis and compute the results\n",
    "for diagnosis in expected_attributes_df.index:\n",
    "    expected = set(expected_attributes_df.columns[expected_attributes_df.loc[diagnosis]==1])\n",
    "    observed = set(significance_boolean.columns[significance_boolean.loc[diagnosis]==1])\n",
    "    expected_and_observed = expected & observed\n",
    "    expected_but_not_observed = expected - observed\n",
    "    not_expected_but_observed = observed - expected\n",
    "    results.loc[diagnosis] = [expected_and_observed,expected_but_not_observed, not_expected_but_observed]\n",
    "\n",
    "# print the results\n",
    "display(results)\n",
    "results.to_excel('/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/final_predictions/expect_table.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all dataframes are nice, now we calculate bar size based on these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_df = proportion_df.sort_index()\n",
    "disease_counts = disease_counts.sort_index()\n",
    "general_mean_multi = general_mean_multi.sort_index()\n",
    "significance_boolean = significance_boolean.sort_index()\n",
    "# display(flattened.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERTICAL BARPLOT\n",
    "attribute_bar = pd.DataFrame(flattened[list(general_mean_multi.columns)].sum(),columns=['Attribute'])\n",
    "attribute_bar['freq']=(attribute_bar['Attribute']*-2)/attribute_bar['Attribute'].max()\n",
    "print('attributes min max')\n",
    "print(attribute_bar['Attribute'].max())\n",
    "print(attribute_bar['Attribute'].min())\n",
    "print(attribute_bar['freq'].max())\n",
    "print(attribute_bar['freq'].min())\n",
    "display(attribute_bar)\n",
    "freq =attribute_bar['freq'].tolist()\n",
    "\n",
    "# Get positions for attribute barplots\n",
    "positions = np.arange(start=.5, stop=.5*len(list(general_mean_multi.columns))*2, step=1)\n",
    "print(len(positions))\n",
    "\n",
    "if cd == False:\n",
    "    disease_counts['freq']= (disease_counts[grouper]*2)/disease_counts[grouper].max()\n",
    "    print('diagnoses max min')\n",
    "    print(disease_counts[grouper].max())\n",
    "    print(disease_counts[grouper].min())\n",
    "    print(disease_counts['freq'].max())\n",
    "    print(disease_counts['freq'].min())\n",
    "    display(disease_counts)\n",
    "    prop_freq_diag = disease_counts['freq'].tolist()\n",
    "    print(prop_freq_diag)\n",
    "\n",
    "if cd == True:\n",
    "    disease_counts['freq']= (disease_counts[grouper]*2)/disease_counts[grouper].max()\n",
    "    print('diagnoses max min')\n",
    "    print(disease_counts[grouper].max())\n",
    "    print(disease_counts[grouper].min())\n",
    "    print(disease_counts['freq'].max())\n",
    "    print(disease_counts['freq'].min())\n",
    "    display(disease_counts)\n",
    "    prop_freq_diag = disease_counts['freq'].tolist()\n",
    "    print(prop_freq_diag)\n",
    "\n",
    "\n",
    "diag_pos = np.arange(start=.5, stop=.5*(len(prop_freq_diag))*2, step=1)\n",
    "print(diag_pos)\n",
    "print(attribute_bar.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_colors = []\n",
    "\n",
    "for col in list(general_mean_multi.columns):\n",
    "#     print(col)\n",
    "    for g in group_dict_fancy:\n",
    "#         print(g)\n",
    "        if col in group_dict_fancy[g]:\n",
    "#             print('grouping: {}'.format(g))\n",
    "            added_colors.append(color_dict_fancy[g])\n",
    "#         print('\\n')\n",
    "#         print(col)\n",
    "\n",
    "print(len(added_colors))\n",
    "print(added_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = int(len(proportion_df.columns)/2)+2\n",
    "if train_plot == False:\n",
    "    num = 84\n",
    "if train_plot == True:\n",
    "    num = 90 ## for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first40_colnames = proportion_df.columns[0:42]\n",
    "first40_colnames = proportion_df.columns\n",
    "# first40_colnames = ['Communication impairment', 'Unable to concentrate',\n",
    "#        'Sleep Disorders, Circadian Rhythm', 'Fatigue', 'Headache', 'Seizures',\n",
    "#        'Sleep disturbances', 'Stress', 'Vivid dreaming', 'Weight loss',\n",
    "#        'Admission to nursing home', 'Cachexia', 'Day Care, Medical',\n",
    "#        'General health deterioration', 'Activities of daily living impaired',\n",
    "#        'Markedly reduced dietary intake']\n",
    "# first40_colnames = [ 'Bradykinesia','Expressionless face', 'Parkinsonism', 'Muscle Rigidity', 'Tremor',\n",
    "#        'Ataxia', 'Equilibration disorder', 'Loss of coordination', 'Nystagmus',\n",
    "#        'Vertigo', 'Dysarthria', 'Muscular fasciculation',\n",
    "#        'Hyperreflexia and other pathological reflexes', 'Muscle Weakness',\n",
    "#        'Muscle Spasticity', 'Swallowing problem',\n",
    "#        'Decreased (fine) motor skills', 'Frequent falls', 'Impaired mobility']\n",
    "# first40_colnames = ['Constipation', 'Hypotension, Orthostatic', 'Urinary Incontinence',\n",
    "#        'Other urinary problems', 'Hearing problem',\n",
    "#        'Negative sensory symptoms', 'Olfactory and gustatory dysfunction',\n",
    "#        'Positive sensory symptoms', 'Visual Impairment']\n",
    "# first40_colnames = ['Aphasia', 'Apraxias',\n",
    "#        'Executive dysfunction', 'Faade behavior', 'Anosognosia',\n",
    "#        'Lack of planning / organization / overview', 'Verbal impairment',\n",
    "#        'Anomia', 'Amnesia', 'Bradyphrenia', 'Cognitive decline',\n",
    "#        'Confabulation', 'Dementia', 'Forgetful', 'Agnosia',\n",
    "#        'Poor short-term memory', 'Memory impairment', 'Apathy',\n",
    "#        'Social disinihibition', 'Hyperorality','Lack of initiative',\n",
    "#        'Socially inappropriate behavior']\n",
    "# first40_colnames = ['Admission to psychiatric hospital',\n",
    "#        'Feeling suicidal', 'Confusion', 'Delirium', 'Delusions',\n",
    "#        'Disorientation', 'Hallucinations', 'Paranoia', 'Psychosis',\n",
    "#        'Wandering Behavior', 'Aggressive behavior', 'Agitation', 'Anxiety',\n",
    "#        'Changed moods or emotions', 'Compulsive behavior', 'Depressed mood',\n",
    "#        'Manic', 'Restlessness']\n",
    "    \n",
    "num = len(first40_colnames)\n",
    "first40_colors = added_colors[0:num]\n",
    "first40_colors =  added_colors\n",
    "print(first40_colnames)\n",
    "print(len(first40_colnames))\n",
    "print(num)\n",
    "# print(proportion_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "proportion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "disease_counts#[grouper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set(style=\"darkgrid\", font_scale=1.5, rc={'axes.facecolor':'#F0E6EB', \"grid.linestyle\": \"-\",\"grid.color\": '#b0b0b0'})\n",
    "\n",
    "##PLOT \n",
    "w = disease_counts.shape[0]/1\n",
    "w = (10+ disease_counts.shape[0]/1)-2\n",
    "h = 2+num/3\n",
    "w = 16\n",
    "h= 27\n",
    "fig = plt.figure(figsize=(w,h ),dpi=200)\n",
    "print('figsize:',w,h)\n",
    "# fig = plt.figure(figsize=(15, 20))\n",
    "ax1 = plt.subplot2grid((9,9), (0, 0), colspan=8,rowspan=9)\n",
    "\n",
    "# #Dots for expected attributes per disease\n",
    "ax1 = scattermap(expected_attributes_df[first40_colnames].T,\n",
    "                marker='o',\n",
    "                marker_size=proportion_df[first40_colnames].T*expected_attributes_df[first40_colnames].T * 1.3,\n",
    "                cmap=\"Oranges\",\n",
    "                cbar=False,ax=ax1)\n",
    "\n",
    "##Dots for proportions and averages \n",
    "ax1 = scattermap(general_mean_multi[first40_colnames].T,\n",
    "                cmap=\"YlGnBu\",\n",
    "                marker_size=proportion_df[first40_colnames].T,\n",
    "                ax=ax1,\n",
    "                vmax=5,\n",
    "                 linecolor = 'black',\n",
    "                 linewidths = 0.2,\n",
    "                 \n",
    "                cbar_kws={\"shrink\": .5})#cbar_kws = {\"orientation\": \"horizontal\", \"pad\":0.02}\n",
    "#                 cbar_kws = dict(use_gridspec=True,location=\"right\"))#,\n",
    "#                 cbar=False)\n",
    "\n",
    "#Significance \n",
    "ax1 = scattermap(significance_boolean[first40_colnames].T,\n",
    "                marker='*',\n",
    "                marker_size=significance_boolean[first40_colnames].T * 100,\n",
    "                cbar=False,\n",
    "                ax=ax1,\n",
    "                 linecolor = 'black',\n",
    "                 linewidths = 0.2,\n",
    "                cmap=\"Wistia\")\n",
    "\n",
    "# x axis on top\n",
    "ax1.xaxis.tick_top() \n",
    "ax1.xaxis.set_label_position('top')\n",
    "# plt.xticks(rotation=75) (old, no subplot)\n",
    "ax1.tick_params('x', labelrotation=90)\n",
    "\n",
    "# Add frequencies of attributes as barplot to y-axis\n",
    "ax1.barh(list(positions)[:num], freq[0:num], 0.6, alpha=1, color=first40_colors,edgecolor = \"none\")\n",
    "# plt.axvline(x=0, color='k') (old, no subplot)\n",
    "ax1.axvline(x=0, color='k')\n",
    "ax1.axhline(0, color='k')\n",
    "\n",
    "ax1.set_xlim([attribute_bar['freq'].min()-0.1,disease_counts.shape[0]])\n",
    "\n",
    "# Add frequencies of diagnosis as barplot to x-axis\n",
    "ax1.bar(diag_pos, prop_freq_diag, 0.6,color='#41b6c4',bottom=num,edgecolor = \"none\")\n",
    "\n",
    "ax1.set_ylim([0,num+disease_counts['freq'].max()+0.1])\n",
    "\n",
    "# plt.title('{}: {} to {} diagnoses, {} to {} attributes, for {} donors'.format(table_of_choice,\n",
    "#                                                                              disease_counts[grouper].min(),\n",
    "#                                                                              disease_counts[grouper].max(),\n",
    "#                                                                              attribute_bar['Attribute'].min(),\n",
    "#                                                                              attribute_bar['Attribute'].max(),\n",
    "#                                                                              selected_donorcountpredict))\n",
    "\n",
    "## same size legend\n",
    "ax2 = plt.subplot2grid((9, 9), (3, 8),colspan=1,rowspan=1)\n",
    "x = [2,3,4,5]\n",
    "y = [2,3,4,5]\n",
    "a2 = [75,150,225,300]\n",
    "\n",
    "sc = ax2.scatter(x, y, s=a2, alpha=0.5,c='white')\n",
    "L = ax2.legend(*sc.legend_elements(\"sizes\"),loc='center left', bbox_to_anchor=(1, 0.7),frameon=False)\n",
    "L.get_texts()[0].set_text('25%')\n",
    "L.get_texts()[1].set_text('50%')\n",
    "L.get_texts()[2].set_text('75%')\n",
    "L.get_texts()[3].set_text('100%')\n",
    "\n",
    "ax2.axis('off')\n",
    "\n",
    "ax3 = plt.subplot2grid((9, 9), (2, 8),colspan=1,rowspan=1)\n",
    "x2 = [2]\n",
    "x3 = [2]\n",
    "y2 = [2]\n",
    "y3 = [2]\n",
    "a3 = [300]\n",
    "t = ['significance','expected']\n",
    "ax3.scatter(x2, y2, s=a3, alpha=1,c='#E59400', marker='*')\n",
    "ax3.scatter(x3, y3, s=a3, alpha=1,facecolors='none',edgecolors='#E59400')\n",
    "ax3.legend(t, loc='center left',bbox_to_anchor=(1, 0.3),frameon=False)\n",
    "ax3.set_ylim([0,1])\n",
    "ax3.set_xlim([0,1])\n",
    "ax3.axis('off')\n",
    "\n",
    "# print('based on table {}'.format(table_of_choice))\n",
    "print(disease_counts.shape[0])\n",
    "print('{} to {} diagnosis, {} to {} attributes'.format(disease_counts[grouper].min(),\n",
    "                                                         disease_counts[grouper].max(),\n",
    "                                                         attribute_bar['Attribute'].min(),\n",
    "                                                         attribute_bar['Attribute'].max() ))\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"{}/dotplot_{}.png\".format(table_folder,table_of_choice), bbox_inches=\"tight\")\n",
    "# plt.savefig(\"{}/dotplot_{}.pdf\".format(table_folder,table_of_choice), bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = int(len(proportion_df.columns)/2)+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first40_colnames = proportion_df.columns[num:]\n",
    "first40_colors = added_colors[num:]\n",
    "print(first40_colnames)\n",
    "num2 = len(first40_colnames)\n",
    "print(num2)\n",
    "# print(proportion_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = h - (((h-2)/num)*(abs(num2-num)))\n",
    "w2 = (h2*w)/h\n",
    "print(w2,h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set(style=\"darkgrid\", font_scale=1.5, rc={'axes.facecolor':'#F0E6EB', \"grid.linestyle\": \"-\",\"grid.color\": '#b0b0b0'})\n",
    "\n",
    "##PLOT \n",
    "# Define plot size. Alter second value to change y-axis size\n",
    "# fig, ax = plt.subplots(figsize=(disease_counts.shape[0]/1.5, 35)) (old, no subplot)\n",
    "# fig, (ax1, ax2) = plt.subplots(1,2,figsize=(disease_counts.shape[0]/1.5, 35))\n",
    "\n",
    "# fig = plt.figure(figsize=(disease_counts.shape[0]/1, 2+num2/2.4))\n",
    "w2=16\n",
    "fig = plt.figure(figsize=(w2, h2),dpi=200)\n",
    "print('figsize:',w2,h2)\n",
    "# fig = plt.figure(figsize=(15, 20))\n",
    "ax1 = plt.subplot2grid((9,9), (0, 0), colspan=8,rowspan=9)\n",
    "\n",
    "# ##Dots for expected attributes per disease\n",
    "ax1 = scattermap(expected_attributes_df[first40_colnames].T,\n",
    "                marker='o',\n",
    "                marker_size=proportion_df[first40_colnames].T*expected_attributes_df[first40_colnames].T * 1.3,\n",
    "                cmap=\"Wistia\",\n",
    "                cbar=False,ax=ax1)\n",
    "\n",
    "##Dots for proportions and averages \n",
    "ax1 = scattermap(general_mean_multi[first40_colnames].T,\n",
    "                cmap=\"YlGnBu\",\n",
    "                marker_size=proportion_df[first40_colnames].T,\n",
    "                ax=ax1,\n",
    "                vmax=5,\n",
    "                 \n",
    "                 linecolor = 'black',\n",
    "                 linewidths = 0.2,\n",
    "                cbar_kws={\"shrink\": .5})#cbar_kws = {\"orientation\": \"horizontal\", \"pad\":0.02}\n",
    "#                 cbar_kws = dict(use_gridspec=True,location=\"right\"))#,\n",
    "#                 cbar=False)\n",
    "\n",
    "#Significance \n",
    "ax1 = scattermap(significance_boolean[first40_colnames].T,\n",
    "                marker='*',\n",
    "                marker_size=significance_boolean[first40_colnames].T * 100,\n",
    "                cbar=False,\n",
    "                ax=ax1,\n",
    "                 \n",
    "                 linecolor = 'black',\n",
    "                 linewidths = 0.2,\n",
    "                cmap=\"Wistia\")\n",
    "\n",
    "# x axis on top\n",
    "ax1.xaxis.tick_top() \n",
    "ax1.xaxis.set_label_position('top')\n",
    "# plt.xticks(rotation=75) (old, no subplot)\n",
    "ax1.tick_params('x', labelrotation=75)\n",
    "\n",
    "# Add frequencies of attributes as barplot to y-axis\n",
    "ax1.barh(list(positions)[:num2], freq[num:], 0.6, alpha=1, color=first40_colors,edgecolor = \"none\")\n",
    "# plt.axvline(x=0, color='k') (old, no subplot)\n",
    "ax1.axvline(x=0, color='k')\n",
    "ax1.axhline(0, color='k')\n",
    "\n",
    "#plt.xlim(attribute_bar['freq'].min()-0.1,disease_counts.shape[0])(old, no subplot)\n",
    "ax1.set_xlim([attribute_bar['freq'].min()-0.1,disease_counts.shape[0]])\n",
    "\n",
    "# Add frequencies of diagnosis as barplot to x-axis\n",
    "ax1.bar(diag_pos, prop_freq_diag, 0.6,color='#41b6c4',bottom=num2,edgecolor = \"none\")\n",
    "\n",
    "# plt.ylim(0,80+disease_counts['freq'].max()+0.1)(old, no subplot)\n",
    "ax1.set_ylim([0,num2+disease_counts['freq'].max()+0.1])\n",
    "\n",
    "plt.title('{}: {} to {} diagnoses, {} to {} attributes, for {} donors'.format(table_of_choice,\n",
    "                                                                             disease_counts['neuropathological_diagnosis'].min(),\n",
    "                                                                             disease_counts['neuropathological_diagnosis'].max(),\n",
    "                                                                             attribute_bar['Attribute'].min(),\n",
    "                                                                             attribute_bar['Attribute'].max(),\n",
    "                                                                             selected_donorcountpredict))\n",
    "ax2 = plt.subplot2grid((9, 9), (3, 8),colspan=1,rowspan=1)\n",
    "x = [2,3,4,5]\n",
    "y = [2,3,4,5]\n",
    "a2 = [75,150,225,300]\n",
    "\n",
    "sc = ax2.scatter(x, y, s=a2, alpha=0.5,c='white')\n",
    "L = ax2.legend(*sc.legend_elements(\"sizes\"),loc='center left', bbox_to_anchor=(1, 0.7),frameon=False)\n",
    "L.get_texts()[0].set_text('25%')\n",
    "L.get_texts()[1].set_text('50%')\n",
    "L.get_texts()[2].set_text('75%')\n",
    "L.get_texts()[3].set_text('100%')\n",
    "\n",
    "ax2.axis('off')\n",
    "\n",
    "ax3 = plt.subplot2grid((9, 9), (2, 8),colspan=1,rowspan=1)\n",
    "x2 = [2]\n",
    "x3 = [2]\n",
    "y2 = [2]\n",
    "y3 = [2]\n",
    "a3 = [300]\n",
    "t = ['significance','expected']\n",
    "ax3.scatter(x2, y2, s=a3, alpha=1,c='#E59400', marker='*')\n",
    "ax3.scatter(x3, y3, s=a3, alpha=1,facecolors='none',edgecolors='#E59400')\n",
    "ax3.legend(t, loc='center left',bbox_to_anchor=(1, 0.3),frameon=False)\n",
    "ax3.set_ylim([0,1])\n",
    "ax3.set_xlim([0,1])\n",
    "ax3.axis('off')\n",
    "\n",
    "print('based on table {}'.format(table_of_choice))\n",
    "print(disease_counts.shape[0])\n",
    "print('{} to {} diagnosis, {} to {} attributes'.format(disease_counts['neuropathological_diagnosis'].min(),\n",
    "                                                         disease_counts['neuropathological_diagnosis'].max(),\n",
    "                                                         attribute_bar['Attribute'].min(),\n",
    "                                                         attribute_bar['Attribute'].max() ))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"{}/dotplot_2{}.png\".format(table_folder,table_of_choice), bbox_inches=\"tight\")\n",
    "plt.savefig(\"{}/dotplot_2{}.pdf\".format(table_folder,table_of_choice), bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_testing_of_dataframes(expected_attributes_df, significance_boolean_df):\n",
    "    ##Function to calculate the Chi-square statistic to deteremine the overlap between the significance boolean dataframe and expected dataframe\n",
    "    import scipy\n",
    "    ###Chi-square testing\n",
    "    boolean_matrix = (expected_attributes_df == 1) & (significance_boolean_df ==1)\n",
    "    category00 = np.sum(np.sum((boolean_matrix * 1)))\n",
    "    boolean_matrix = (expected_attributes_df == 0) & (significance_boolean_df ==1)\n",
    "    category01 = np.sum(np.sum((boolean_matrix * 1)))\n",
    "    boolean_matrix = (expected_attributes_df == 1) & (significance_boolean_df ==0)\n",
    "    category10 = np.sum(np.sum((boolean_matrix * 1)))\n",
    "    boolean_matrix = (expected_attributes_df == 0) & (significance_boolean_df ==0)\n",
    "    category11 = np.sum(np.sum((boolean_matrix * 1)))\n",
    "    observations = np.array([[category00,category01], [category10, category11]])\n",
    "    chi2, p, dof, expected = scipy.stats.chi2_contingency(observations)\n",
    "    print(f\"chi2 statistic:   {chi2:.5g}\")\n",
    "    print(f\"p-value:      {p:.5g}\")\n",
    "    print(f\"degrees of freedom: {dof}\")\n",
    "    print()\n",
    "    print(\"expected frequencies:\")\n",
    "    print(expected)\n",
    "    print()\n",
    "    print(\"observed frequencies:\")\n",
    "    print(observations)\n",
    "    \n",
    "chi_square_testing_of_dataframes(expected_attributes_df, significance_boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning_env",
   "language": "python",
   "name": "machine_learning_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
