{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11eaa06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e4dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_predictions = \"/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/final_predictions/ALL_clinical_trajectories_dictionary_rules_of_thumb_yearly_2023-01-31.pkl\"\n",
    "path_to_predictions = \"/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/final_predictions/ALL_clinical_trajectories_dictionary_rules_of_thumb_yearly_2023-07-11.pkl\"\n",
    "output_path = \"/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/temporal_model/data\"\n",
    "general_information = \"/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/input_data/General_information_20-07-2023.xlsx\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc7d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kernel: simplemodels3\n",
    "#Python version on web portal: 3.9.5\n",
    "from __future__ import absolute_import, division, print_function\n",
    "# import seaborn as sns; sns.set()\n",
    "import numpy as np; np.random.seed(0)\n",
    "# from matplotlib import pyplot as plt \n",
    "\n",
    "import xlsxwriter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn import model_selection \n",
    "from collections import Counter\n",
    "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix\n",
    "from natsort import natsorted\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/scripts')\n",
    "from helper_functions import table_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c0a49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_path):\n",
    "    print('Creating output folder....')\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5573f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_predictions,\"rb\") as file:\n",
    "    predictions_pickle = pickle.load(file)\n",
    "\n",
    "d = []\n",
    "for i,j in zip(predictions_pickle,predictions_pickle.values()):\n",
    "    k = pd.DataFrame.from_dict(j,orient=\"index\")\n",
    "    k[\"DonorID\"] = i\n",
    "    k['Age'] = k.index\n",
    "    d.append(k)\n",
    "predictions_df =pd.concat(d, ignore_index=True)\n",
    "\n",
    "print(f\"there are {len(list(predictions_df['DonorID'].unique()))} unique donor IDs\")\n",
    "print(predictions_df.shape)\n",
    "# display(predictions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626cf039-91c1-4e2b-b89e-927e5388a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_information_df = pd.read_excel(general_information, engine='openpyxl', sheet_name=\"Sheet1\")\n",
    "donors_to_remove = list(general_information_df[general_information_df['paper diagnosis']=='exclude'].DonorID)\n",
    "predictions_df = predictions_df[~predictions_df['DonorID'].isin(donors_to_remove)]\n",
    "print(f\"there are {len(list(predictions_df['DonorID'].unique()))} unique donor IDs\")\n",
    "print(len(donors_to_remove))\n",
    "predictions_df['neuropathological_diagnosis'] = predictions_df['DonorID'].map(general_information_df.set_index('DonorID')['paper diagnosis'])\n",
    "display(predictions_df.head())\n",
    "print(sorted(predictions_df['neuropathological_diagnosis'].unique()))\n",
    "print(f\"there are {len(list(predictions_df['DonorID'].unique()))} unique donor IDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbc9316",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = predictions_df.copy()\n",
    "# trajectories = trajectories.drop(['Year'], axis=1)\n",
    "unique_diagnoses = trajectories[['DonorID', 'neuropathological_diagnosis']].drop_duplicates()\n",
    "display(unique_diagnoses['neuropathological_diagnosis'].value_counts().head(20))\n",
    "display(trajectories.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ee320e-1730-4355-ad1c-f79ac2ef2a5f",
   "metadata": {},
   "source": [
    "### remove donors before 1997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2346a9ea-4e29-4600-b384-da65ea818de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories['file_year'] = trajectories['DonorID'].str.extract(r'NBB (\\d{4})-\\d{3}', expand=False)\n",
    "trajectories['file_year'] = pd.to_numeric(trajectories['file_year'])\n",
    "trajectories = trajectories[trajectories['file_year'] >= 1997]\n",
    "display(trajectories.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847e0ea5-b663-471d-9c94-6e8fff4dda7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_diagnoses = trajectories[['DonorID', 'neuropathological_diagnosis']].drop_duplicates()\n",
    "unique_diagnoses['neuropathological_diagnosis'].value_counts().head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e430db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1 ## obs\n",
    "n = 5 ## years ## we also use this one to select for how many total observations \n",
    "## 5 means with flattened, 6 means without\n",
    "remove3 = True\n",
    "observation = False\n",
    "unique = False\n",
    "eighties = False\n",
    "remove_diagnoses = ['DLB','ATAXIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d14aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_attribute_columns = ['DonorID','Age','neuropathological_diagnosis','age_at_death','Year','sex','file_year'] #'death_year_based_on_DonorID'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a955064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trajectories = trajectories.sort_values(['DonorID', 'Age'],\n",
    "              ascending = [True, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3250f71c",
   "metadata": {},
   "source": [
    "### Select only table 1 cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd50c7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_diagnoses, ordered_diagnoses = table_selector('table1_p', trajectories)\n",
    "print('After selecting for {}, we have {} sentences belonging to {} donors'.format(selected_diagnoses['neuropathological_diagnosis'].unique(),\n",
    "                                                                                    selected_diagnoses.shape[0],\n",
    "                                                                                    selected_diagnoses['DonorID'].nunique()) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef1256-e448-421c-a1a6-e8f15ae44153",
   "metadata": {},
   "source": [
    "### remove/add/merge some diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9700205-a5cb-4123-9014-8604022ac3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PDD into PD\n",
    "selected_diagnoses['neuropathological_diagnosis'] = selected_diagnoses['neuropathological_diagnosis'].replace('PDD', 'PD')\n",
    "## add D,DLB\n",
    "selected_diagnoses = pd.concat([selected_diagnoses, trajectories[trajectories['neuropathological_diagnosis'] == 'AD,DLB']], ignore_index=True)\n",
    "# remove psych\n",
    "selected_diagnoses = selected_diagnoses[selected_diagnoses['neuropathological_diagnosis'] != 'MDD']\n",
    "selected_diagnoses = selected_diagnoses[selected_diagnoses['neuropathological_diagnosis'] != 'BP']\n",
    "selected_diagnoses = selected_diagnoses[selected_diagnoses['neuropathological_diagnosis'] != 'SCZ']\n",
    "display(selected_diagnoses.head())\n",
    "unique_diagnoses = selected_diagnoses[['DonorID', 'neuropathological_diagnosis']].drop_duplicates()\n",
    "unique_diagnoses['neuropathological_diagnosis'].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc77406",
   "metadata": {},
   "source": [
    "### remove observations without yearly information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8ef3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_diagnoses = selected_diagnoses[selected_diagnoses.Age >= 0]\n",
    "selected_diagnoses = selected_diagnoses.reset_index(drop=True)\n",
    "unique_diagnoses = selected_diagnoses[['DonorID', 'neuropathological_diagnosis']].drop_duplicates()\n",
    "unique_diagnoses['neuropathological_diagnosis'].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d972954c-251d-4e36-92e6-603de3931392",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_diagnoses = selected_diagnoses.sort_values(['DonorID', 'Age'],\n",
    "              ascending = [True, True])\n",
    "selected_diagnoses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c54c03",
   "metadata": {},
   "source": [
    "#### DONORS with a diagnosis need at least n years with at least m observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3376be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## how many observations has each donor?\n",
    "data = selected_diagnoses.copy()\n",
    "# display(data.groupby('DonorID')['Age'].nunique())\n",
    "\n",
    "## df showing number of observations\n",
    "data2 = data.drop(columns=['age_at_death','sex','Age','file_year'])\n",
    "data2 = data2.groupby(['DonorID','neuropathological_diagnosis']).sum()\n",
    "data2 = pd.DataFrame(data2.sum(axis=1),columns=['count'])\n",
    "data2 = data2.reset_index()  \n",
    "data2 = data2.set_index('DonorID')\n",
    "data2['uniqueage'] = data.groupby('DonorID')['Age'].nunique()\n",
    "display(data2)\n",
    "\n",
    "## con are the exception, they are allowed to have little data\n",
    "data3 = data2[data2['neuropathological_diagnosis'] != 'CON']\n",
    "donors_not_enough_data = data3.index[data3['count'] < 5].tolist()\n",
    "\n",
    "print(donors_not_enough_data)\n",
    "print(len(donors_not_enough_data))\n",
    "data = data[~data['DonorID'].isin(donors_not_enough_data)]\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "unique_diagnoses = data[['DonorID', 'neuropathological_diagnosis']].drop_duplicates()\n",
    "unique_diagnoses['neuropathological_diagnosis'].value_counts().head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a78128",
   "metadata": {},
   "source": [
    "## for figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c77767",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data['DonorID'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38944b1",
   "metadata": {},
   "source": [
    "### creating data for model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d85970",
   "metadata": {},
   "source": [
    "#### INPUT\n",
    "array of arrays. each array is for a single donor, consisting of shape time x attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f8903f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp = data.copy()\n",
    "inp = inp.drop(['neuropathological_diagnosis','file_year','age_at_death'],axis=1)\n",
    "inp['sex'] = inp['sex'].map({'F': 1, 'M': 0}).astype(int)\n",
    "inp['Age']  = inp['Age'].astype(int)\n",
    "def sum_except_donors(df):\n",
    "    return df.iloc[:, ].sum()\n",
    "\n",
    "inp = inp.sort_values(['DonorID', 'Age'],\n",
    "              ascending = [True, True])\n",
    "\n",
    "inp_with_nan = inp.copy()\n",
    "inp_with_nan = inp_with_nan.reset_index(drop=True)\n",
    "display(inp_with_nan)\n",
    "final_input = inp_with_nan.set_index('DonorID').groupby('DonorID').apply(pd.DataFrame.to_numpy).to_numpy()\n",
    "print(final_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94405fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_input.shape)\n",
    "print(final_input[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56518f1d",
   "metadata": {},
   "source": [
    "#### LABEL TASKNAME\n",
    "\n",
    "array in the shape samples X diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2bcc8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=30)\n",
    "lt = data[['DonorID','neuropathological_diagnosis']].copy()\n",
    "# lt = lt[~lt['DonorID'].isin(weirds)]\n",
    "lt = lt.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "display(lt)\n",
    "\n",
    "donorcount = len(lt['DonorID'])\n",
    "print(donorcount)\n",
    "print(lt['neuropathological_diagnosis'].value_counts())\n",
    "print(lt.neuropathological_diagnosis.unique())\n",
    "\n",
    "one_hot = pd.get_dummies(lt.neuropathological_diagnosis)\n",
    "\n",
    "# Define the ordered list\n",
    "wanted = ['CON', 'AD', 'PD', 'VD', 'FTD','DLB','AD,DLB','ATAXIA', 'MND', 'PSP', 'MS','MSA'] #'AD,DLB' 'DLB,SICC',\n",
    "\n",
    "# Get the current columns of the dataframe\n",
    "current_cols = list(one_hot.columns)\n",
    "\n",
    "# Create a new list of columns in the order of the 'wanted' list\n",
    "new_cols = [col for col in wanted if col in current_cols]\n",
    "\n",
    "# Reorder the columns of the dataframe using the new list of columns\n",
    "one_hot = one_hot.reindex(columns=new_cols)\n",
    "display(one_hot)\n",
    "final_label_taskname = one_hot.to_numpy()\n",
    "display(final_label_taskname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829a656d",
   "metadata": {},
   "source": [
    "#### MASKING\n",
    "Masking is a datatype of the same shape as input. it is used to indicate which data is present, and which data is absent. If a row of data would be [nan, nan, 0, 0, 3.14, 10], the masking row would be [0,0,1,1,1,1]. In our case, we have options:\n",
    "- every value larger than 1 to 1, every zero to zero. because a zero can mean that the symptom is present, it is just not written down that year?\n",
    "- every value to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a308e-8075-4717-8932-1346b301ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d6196-d62e-4b88-b046-331156b45dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "final_masking = copy.deepcopy(final_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(final_masking)):\n",
    "    final_masking[k][final_masking[k] >= 0] = 1    \n",
    "\n",
    "print(final_masking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9bd5e2",
   "metadata": {},
   "source": [
    "#### TIMESTAMP\n",
    "Timestamp is another array of arrays. There is an array for every donor, that consists of the timepoints that are known for that donor. e.g. if donor1 has information from age 34, 61, and 62, then his timestamp would be [34,61,62]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e390906",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_df = inp[['DonorID','Age']].copy()\n",
    "timestamp_df\n",
    "final_timestamp = timestamp_df.set_index('DonorID').groupby('DonorID').apply(pd.DataFrame.to_numpy).to_numpy()\n",
    "final_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ae30a",
   "metadata": {},
   "source": [
    "### SPLITTING BALANCED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f4c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function takes the created train and test data as input\n",
    "## it returns a measure of how similar train is to test\n",
    "## it also shows an overview of the number of cases per attribute\n",
    "## and a corrected version of this overview\n",
    "def split_vis(x_train,x_test,y_train, y_test,train_val_size,test_size):\n",
    "    \"\"\"\n",
    "    something\n",
    "    \"\"\"\n",
    "    counts = {}\n",
    "    counts[\"train_counts\"] = Counter(str(combination) for row in get_combination_wise_output_matrix(\n",
    "        y_train, order=1) for combination in row)\n",
    "    counts[\"test_counts\"] = Counter(str(combination) for row in get_combination_wise_output_matrix(\n",
    "        y_test, order=1) for combination in row)    \n",
    "\n",
    "    # view distributions\n",
    "    multi_split_dist = pd.DataFrame({\n",
    "        \"for_train_and_val\": counts[\"train_counts\"],\n",
    "        \"test\": counts[\"test_counts\"]\n",
    "    }).T.fillna(0)\n",
    "    multi_split_dist = multi_split_dist.reindex(natsorted(multi_split_dist.columns), axis=1)\n",
    "#     multi_split_dist.columns = labels\n",
    "    \n",
    "    for k in counts[\"test_counts\"].keys():\n",
    "        counts[\"test_counts\"][k] = int(counts[\"test_counts\"][k] * (train_val_size/test_size))\n",
    "        \n",
    "    # View size corrected distributions\n",
    "    multi_split_dist_corr = pd.DataFrame({\n",
    "        \"for_train_and_val\": counts[\"train_counts\"],\n",
    "        \"test\": counts[\"test_counts\"]\n",
    "    }).T.fillna(0)\n",
    "    multi_split_dist_corr =multi_split_dist_corr.reindex(natsorted(multi_split_dist_corr.columns), axis=1)\n",
    "#     multi_split_dist_corr.columns = labels\n",
    "    \n",
    "    print(f\"train: {len(x_train)} ({len(x_train)/(len(x_train)+len(x_test)):.2f})\\n\"\n",
    "          f\"test: {len(x_test)} ({len(x_test)/(len(x_train)+len(x_test)):.2f})\")\n",
    "    dist_split = np.mean(np.std(multi_split_dist_corr.to_numpy(), axis=0))\n",
    "    \n",
    "    return dist_split,multi_split_dist,multi_split_dist_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ffcf58",
   "metadata": {},
   "source": [
    "## for figure 5, counts for split are in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c591e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if eighties == True:\n",
    "    n_split = 10 # 5 for 60-20-20, 10 for 80-10-10\n",
    "    n_split_in = 9 # 4 for 60-20-20, 9 for 80-10-10\n",
    "elif eighties == False:\n",
    "    n_split = 5 # 5 for 60-20-20, 10 for 80-10-10\n",
    "    n_split_in = 4 # 4 for 60-20-20, 9 for 80-10-10\n",
    "\n",
    "fold_taskname = np.empty(shape=(5, 3), dtype=object)\n",
    "\n",
    "# X = np.array([0, 2, 1, 1,0,2,0, 2, 1, 1,0,2,0, 2, 1, 1,0,2])\n",
    "# y = np.array([0, 2, 1, 1,0,2,0, 2, 1, 1,0,2,0, 2, 1, 1,0,2])\n",
    "X = np.array(lt['neuropathological_diagnosis'].values)\n",
    "y = np.array(lt['neuropathological_diagnosis'].values)\n",
    "print(y)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "## SET UP SPLIT BETWEEN TEST AND TRAIN/VAL\n",
    "skf = StratifiedKFold(n_splits=n_split, random_state=1, shuffle=True)\n",
    "skf.get_n_splits(X, y)\n",
    "print(skf)\n",
    "j = 0\n",
    "for train_val_index, test_index in skf.split(X, y):\n",
    "#     print(\"TRAIN+VAL:\", train_val_index, \"TEST:\", test_index)\n",
    "    ## USE THE GENERATED INDICES TO SELECT DIAGNOSES\n",
    "    q_train_val, q_test = X[train_val_index], X[test_index]\n",
    "    r_train_val, r_test = y[train_val_index], y[test_index]\n",
    "#     print('test:' , test_index)\n",
    "#     print('trainval: ', train_val_index)\n",
    "    skf2 = StratifiedKFold(n_splits=n_split_in, random_state=2, shuffle=True)\n",
    "    skf2.get_n_splits(X, y)\n",
    "    print(skf2)\n",
    "    \n",
    "    ## WITHIN EACH FOLD, SPLIT TRAIN/VAL INTO TRAIN AND VAL (ONLY NEEDED ONCE!)\n",
    "    i = 0\n",
    "    ## example: \n",
    "    ## [0,1,2,3,4,5,6,7,8,9]  full data ['a','b','c','d','e','f','g','h','i','j']\n",
    "    ## [0,2,3,5,7,9] indices selected for train/val ['a','c','d','f','h','j']\n",
    "    ## [0,1,2,3,4,5]\n",
    "    ## [0,2,3,9] indices points selected for train ['a','c','d','j']\n",
    "    for train_index, val_index in skf2.split(q_train_val, r_train_val):\n",
    "        print(i)\n",
    "        if i == 0:\n",
    "            ## USE THE GENERATED INDICES TO CREATE NEW INDICES THAT WORK ON THE FULL DATA\n",
    "            true_train = train_val_index[train_index]\n",
    "            true_val = train_val_index[val_index]\n",
    "            \n",
    "            ## PRINT THE INDICES\n",
    "            print(\"TRAIN:\", true_train, \"\\nVAL:\", true_val, \"\\nTEST:\", test_index)\n",
    "            q_train, q_val, q_test = X[true_train], X[true_val],X[test_index]\n",
    "            r_train, r_val, q_test = y[true_train], y[true_val],y[test_index] \n",
    "            \n",
    "            #print('trainval: ',train_val_index,train_val_index.shape )\n",
    "            #print('train: ',train_index, train_index.shape)\n",
    "            print(f\"train: {len(q_train)} ({len(q_train)/(len(q_train)+len(q_test)+len(q_val)):.2f})\\n\"\n",
    "                  f\"val: {len(q_val)} ({len(q_val)/(len(q_train)+len(q_test)+len(q_val)):.2f})\\n\"\n",
    "                  f\"test: {len(q_test)} ({len(q_test)/(len(q_train)+len(q_test)+len(q_val)):.2f})\")\n",
    "            \n",
    "            ## SAVE INTO NUMPY ARRAY\n",
    "            fold_taskname[j][0] = np.asarray(true_train)\n",
    "            fold_taskname[j][1] = np.asarray(true_val)\n",
    "            fold_taskname[j][2] = np.asarray(test_index)\n",
    "            \n",
    "            ## FOR VISUALIZING COUNTS PER DIAGNOSIS PER FOLD\n",
    "            ## TRAINING\n",
    "            foo, bar = np.unique(q_train, return_counts=True)\n",
    "            my_dict = dict(zip(foo, bar))\n",
    "            df = pd.DataFrame(list(my_dict.items()),columns = ['diagnosis','train'])\n",
    "            \n",
    "            ## VALIDATION\n",
    "            foo, bar = np.unique(q_val, return_counts=True)\n",
    "            my_dict = dict(zip(foo, bar))\n",
    "            df1 = pd.DataFrame(list(my_dict.items()),columns = ['diagnosis2','val'])\n",
    "            \n",
    "            ## TEST\n",
    "            foo, bar = np.unique(q_test, return_counts=True)\n",
    "            my_dict = dict(zip(foo, bar))\n",
    "            df2 = pd.DataFrame(list(my_dict.items()),columns = ['diagnosis3','test'])\n",
    "            \n",
    "            ## COMBINE ALL THREE\n",
    "            df3 = pd.concat([df,df1, df2], ignore_index=True,axis=1)\n",
    "            df3.columns = ['diagnosis','train','diagnosis2','val','diagnosis3','test']\n",
    "            df3 = df3.drop(['diagnosis2','diagnosis3'], axis=1)\n",
    "            display(df3)\n",
    "            print(df3['diagnosis'])\n",
    "#         elif i > 0:\n",
    "#             print('finished fold {}, exiting...'.format(i))\n",
    "            break\n",
    "        i = i +1\n",
    "    j = j + 1\n",
    "    print('---------')\n",
    "print(fold_taskname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9581d9-2bc2-436b-b8f0-127b8141b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold_taskname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17dd45-a6a5-4a7b-872b-048dee02b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold_taskname[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dc86e7-5fe4-4ba5-aa79-015503632fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c38a79-f452-437e-8d00-a0b3344eae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_input[fold_taskname[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f352bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.set_printoptions(threshold=np.inf)\n",
    "n_dim = 86#83\n",
    "mean_taskname = np.zeros((5, 1, n_dim)) * np.nan\n",
    "std_taskname = np.zeros((5, 1, n_dim)) * np.nan\n",
    "for i_split in range(5):\n",
    "    ## fold_taskname[i_split][0] selecteert de indexen van de training donors van elke fold\n",
    "    ## final_input[fold_taskname[i_split][0]] selecteerd de training data van deze donoren\n",
    "    ## de concatenate step combineer het, dus x_tr is training data per fold\n",
    "    x_tr = np.concatenate(final_input[fold_taskname[i_split][0]], axis=0)\n",
    "    display(x_tr)\n",
    "    ## mean taskname contains the mean of each training column. eg. for the first fold, the average age is 75\n",
    "    mean_taskname[i_split][0] = np.nanmean(x_tr, axis=0)\n",
    "    ## std taskname contains the std of each training column. eg. for the first fold, the average age is 12\n",
    "    std_taskname[i_split][0] = np.nanstd(x_tr, axis=0)\n",
    "    \n",
    "print(mean_taskname[0][0])\n",
    "print(std_taskname[0][0])\n",
    "mean_taskname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1afb7bb",
   "metadata": {},
   "source": [
    "### SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d4832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if eighties == True:\n",
    "    prefix = '80_'\n",
    "elif eighties == False:\n",
    "    prefix = '60_'\n",
    "    \n",
    "if remove3 == False and observation == False and unique == False:\n",
    "    savespace = '{}clinical_history_{}_years_{}_observations'.format(prefix, str(n),str(m))\n",
    "\n",
    "elif remove3 == False and observation == True and unique == False:\n",
    "    savespace = '{}clinical_history_{}_observations'.format(prefix,str(n))\n",
    "\n",
    "elif remove3 == False and observation == True and unique == True:\n",
    "    savespace = '{}clinical_history_{}_unique_observations'.format(prefix,str(n))\n",
    "                                                          \n",
    "        \n",
    "elif remove3 == True and observation == False and unique == False:\n",
    "    savespace = '{}clinical_history_{}_years_{}_observations_subset'.format(prefix,str(n),str(m))\n",
    "\n",
    "elif remove3 == True and observation == True and unique == False:\n",
    "    savespace = '{}clinical_history_{}_observations_subset'.format(prefix,str(n))\n",
    "    \n",
    "elif remove3 == True and observation == True and unique == True:\n",
    "    savespace = '{}clinical_history_{}_unique_observations_subset'.format(prefix,str(n))\n",
    "    \n",
    "\n",
    "print(savespace)\n",
    "os.makedirs(os.path.join(output_path,  savespace),\n",
    "            exist_ok=True)\n",
    "np.savez(os.path.join(output_path, savespace, 'data.npz'),\n",
    "         input=final_input, masking=final_masking, timestamp=final_timestamp, label_taskname=final_label_taskname)\n",
    "np.savez(os.path.join(output_path, savespace, 'fold.npz'),\n",
    "         fold_taskname=fold_taskname, mean_taskname=mean_taskname, std_taskname=std_taskname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca0fe4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754bddbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788632eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1c1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clinical_history",
   "language": "python",
   "name": "clinical_history"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
