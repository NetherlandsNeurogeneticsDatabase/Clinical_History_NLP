{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netherlands Neurogenetics Database\n",
    "Author: Nienke Mekkes <br>\n",
    "Date: 9-Nov-2022. <br>\n",
    "Correspond: n.j.mekkes@umcg.nl <br>\n",
    "\n",
    "## Script: clinical history predictions\n",
    "Steps: <br>\n",
    "- (when model not yet trained: load cleaned training data)\n",
    "- (when model not yet trained: train model on cleaned training data using optimized hyperparameters)\n",
    "\n",
    "- load trained model\n",
    "- load full corpus of sentences\n",
    "- predict full corpus of sentences with loaded pretrained model\n",
    "- save predictions for further processing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_training_data = \"/home/jupyter-n.mekkes@gmail.com-f6d87/ext_n_mekkes_gmail_com/clinical_history/training_data/cleaned_training_data.xlsx\"\n",
    "predictions_output_path = \"/home/jupyter-n.mekkes@gmail.com-f6d87/ext_n_mekkes_gmail_com/clinical_history/final_predictions\"\n",
    "full_corpus = \"/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/input_data/Clinical_history_15-12-2022.xlsx\"\n",
    "location_of_best_model = \"/home/jupyter-n.mekkes@gmail.com-f6d87/ext_n_mekkes_gmail_com/clinical_history/nlp_models/final_trained_best_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimal requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LOADING PACKAGES...')\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import logging, sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import csv#,random\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import os, re#, string\n",
    "import numpy as np\n",
    "\n",
    "from adjustText import adjust_text\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score,precision_score,recall_score,classification_report \n",
    "\n",
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "from openpyxl import load_workbook, Workbook\n",
    "import xlsxwriter\n",
    "\n",
    "import joblib\n",
    "from datetime import date\n",
    "# import kaleido\n",
    "# import plotly\n",
    "\n",
    "from optuna.visualization import plot_contour,plot_edf,plot_intermediate_values,plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate,plot_param_importances,plot_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel, MultiLabelClassificationArgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(predictions_output_path):\n",
    "    os.makedirs(predictions_output_path)\n",
    "    print(\"creating predictions directory\")\n",
    "\n",
    "if not os.path.exists(location_of_best_model):\n",
    "    os.makedirs(location_of_best_model)\n",
    "    print(\"creating model directory\")\n",
    "\n",
    "df_train = pd.read_excel(cleaned_training_data, engine='openpyxl', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the column names to make predictions df human readable\n",
    "non_attribute_columns = ['NBB_nr','Year_Sentence_nr','Sentence']\n",
    "attributes = [col for col in df_train.columns if col not in non_attribute_columns]\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optional, only when still need to train\n",
    "df_train['labels'] = [x for x in df_train[attributes].to_numpy()]\n",
    "df_train = df_train[['Sentence','labels']]\n",
    "display(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set model args\n",
    "model_args_bert = { \"do_lower_case\": True, # for uncased models\n",
    "       \"fp16\": True,#speeds up, but risk under/overflow\n",
    "       \"learning_rate\":  5.123640376667562e-05, # candidate for optimalisation\n",
    "       \"manual_seed\": 2,\n",
    "       \"max_seq_length\": 300, #Chosen such that most samples are not truncated. Increasing the sequence length significantly affects the memory consumption of the model, so it s usually best to keep it as short as possible (ideally without truncating the input sequences).\n",
    "       \"num_train_epochs\": 33, # option for optimalisation\n",
    "      #\"optimizer\": \"Adafactor\", # option for optimalisation\n",
    "       \"output_dir\": location_of_best_model,\n",
    "       \"overwrite_output_dir\": True,\n",
    "       \"reprocess_input_data\" : True, #default true, input data will be reprocessed even if a cached file of the input data exists.\n",
    "       \"save_eval_checkpoints\":False,\n",
    "       \"save_model_every_epoch\":False,\n",
    "       \"save_optimizer_and_scheduler\":False,\n",
    "       \"save_steps\": -1,\n",
    "       \"silent\":False,\n",
    "      #\"scheduler\": \"linear_schedule_with_warmup\",  # option for optimalisation\n",
    "      #\"sliding_window\": True # not supported, but advised? # option for optimalisation\n",
    "       \"train_batch_size\": 16,  \n",
    "       \"use_multiprocessing\": True, #speeds up,may be unstable, has some issues reported with t5\n",
    "       \"wandb_project\": 'predict',\n",
    "#         \"wandb_kwargs\": {\"mode\":\"disabled\"},\n",
    "       \"threshold\":0.6\n",
    "\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ONLY RUN IF YOUR MODEL IS NOT YET TRAINED!\n",
    "# model = MultiLabelClassificationModel('bert', ## \"bert\" or \"t5\"\n",
    "#                                       \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\", ## \"modelname from huggingface\"\n",
    "#                                       args=model_args_bert,\n",
    "#                                       use_cuda=True,\n",
    "#                                       num_labels=90)\n",
    "\n",
    "# model.train_model(df_train[['Sentence','labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD ALREADY TRAINED MODEL\n",
    "model = MultiLabelClassificationModel('bert', ## \"bert\" or \"t5\"\n",
    "                                      location_of_best_model, ## \"modelname from huggingface\"\n",
    "                                      args=model_args_bert,\n",
    "                                      use_cuda=False,#True,\n",
    "                                      num_labels=90) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load sentences to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "full_corpus_df = pd.read_excel(full_corpus, engine='openpyxl', index_col=None)\n",
    "general_information = \"/home/jupyter-n.mekkes@gmail.com-f6d87/clinical_history/input_data/General_information_20-07-2023.xlsx\"\n",
    "general_information_df = pd.read_excel(general_information, engine='openpyxl', sheet_name=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = full_corpus_df.copy()\n",
    "full_corpus_donors = list(df_predict['DonorID'].unique())\n",
    "gi_donors = list(general_information_df['DonorID'].unique())\n",
    "print(len(full_corpus_donors))\n",
    "print(len(gi_donors))\n",
    "\n",
    "full_corpus_donors_not_in_gi_donors = [item for item in full_corpus_donors if item not in gi_donors]\n",
    "print(full_corpus_donors_not_in_gi_donors)  # Output: [1, 2, 5]\n",
    "\n",
    "gi_donors_not_in_full_corpus_donors = [item for item in gi_donors if item not in full_corpus_donors]\n",
    "print(gi_donors_not_in_full_corpus_donors)  # Output: [6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences_to_remove = ['Past:','Last two years:','Last 2 years:','Last two months:','Last 2 months:','In the past:','0','M.',\n",
    "#                        'January:','February:','March:','April:','May:','June:','July:','August:','September:','October:','November:','December:',\n",
    "#                        'January','February','March','April','May','June','July','August','September','October','November','December'\n",
    "#                       ]\n",
    "# year = \"^[12][0-9]{3}:$\"\n",
    "# year2 = \"^[12][0-9]{3}$\"\n",
    "# year3 = \"^\\([12][0-9]{3}\\)$\"\n",
    "# # years = predictions_df['Sentence'].str.contains(patternDel)\n",
    "# m = df_predict['Sentence'].str.contains(year)\n",
    "# m2 = df_predict['Sentence'].str.contains(year2)\n",
    "# m3 = df_predict['Sentence'].str.contains(year3)\n",
    "# df_predict = df_predict[~m]\n",
    "# df_predict =df_predict[~m2]\n",
    "# df_predict = df_predict[~m3]\n",
    "# df_predict = df_predict[~df_predict['Sentence'].isin(sentences_to_remove)]\n",
    "\n",
    "# short_symptoms = ['tia','uti','copd','gout','coma','pick','cva']\n",
    "# df_predict = df_predict.loc[(df_predict['Sentence'].str.len() > 4) | \\\n",
    "#                       df_predict['Sentence'].str.contains('|'.join(short_symptoms),case=False)]\n",
    "# print(f\"there are {df_predict.shape[0]} sentences and {len(attributes)} columns\")\n",
    "# print(f\"there are {len(list(df_predict['DonorID'].unique()))} unique donor IDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = df_predict['Sentence'].values\n",
    "# Some values are interpreted as double/int, they should be converted to str\n",
    "ps = [str(i) for i in list(ps)]\n",
    "# print(ps[1])\n",
    "# nr = 0\n",
    "# p, raw_outputs = model.predict(list(ps[1]))\n",
    "# print(p)\n",
    "# # pred = np.array(p)\n",
    "# # print(pred)\n",
    "# # print(pred.shape)\n",
    "# # preds_in_df = pd.DataFrame(pred)\n",
    "# # preds_in_df.columns = attributes\n",
    "# # display(preds_in_df)\n",
    "# # display(preds_in_df)\n",
    "# # for i in ps[0:10]:\n",
    "# #     print(nr, i)\n",
    "# #     nr = nr + 1\n",
    "# #     p, raw_outputs = model.predict(list(ps[nr]))\n",
    "# #     pred = np.array(p)\n",
    "# #     # print(pred)\n",
    "# #     # print(pred.shape)\n",
    "# #     preds_in_df = pd.DataFrame(pred)\n",
    "# #     preds_in_df.columns = attributes\n",
    "# #     # display(preds_in_df)\n",
    "# #     df_final_predictions = pd.concat([df_predict, preds_in_df], axis=1)\n",
    "# # display(df_final_predictions.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, raw_outputs = model.predict(list(ps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_predictions.to_excel(f\"{predictions_output_path}/predictions_{date.today()}.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning_env",
   "language": "python",
   "name": "machine_learning_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
