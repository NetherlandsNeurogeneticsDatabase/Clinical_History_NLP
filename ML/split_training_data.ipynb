{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netherlands Neurogenetics Database\n",
    "Author: Nienke Mekkes <br>\n",
    "Date: 21-Sep-2022. <br>\n",
    "Correspond: n.j.mekkes@umcg.nl <br>\n",
    "\n",
    "## Script: clinical history labeled training data: splitting data\n",
    "Objectives: load cleaned training data, split into <br>\n",
    "- test (will be stored separately)\n",
    "- train&val (serves as input for our models)\n",
    "\n",
    "Ideally, the distribution of attributes is similar between the test set and the train/val set. Therefore we stratify the data using the attributes. In other words, our testset will not contain attributes not present in the train&valset, and vice versa. <br>\n",
    "We assume that we do not have to stratify the donors (e.g. on sex, or diagnosis), since our task is predicting attribute labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input files:\n",
    "- excel file with cleaned labeled training data, OR\n",
    "- pickle file with cleaned labeled training data\n",
    "\n",
    "### Output\n",
    "- Folder containing:\n",
    "    - trainval data (excel and pickle)\n",
    "    - test data (excel and pickle)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Minimal requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install openpyxl\n",
    "# %pip install iterative-stratification\n",
    "# %pip install scikit-multilearn\n",
    "# %pip install natsort ?\n",
    "# %pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from datetime import date\n",
    "from helper_functions import split_vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paths (user input required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_cleaned_training_data_xlsx = '/data/p307948/clinical/github_data/output/cleaned_training_data.xlsx'\n",
    "path_to_cleaned_training_data_pkl = \"/home/jupyter-n.mekkes@gmail.com-f6d87/ext_n_mekkes_gmail_com/clinical_history/training_data/cleaned_training_data.pkl\"\n",
    "save_path_files = '/home/jupyter-n.mekkes@gmail.com-f6d87/ext_n_mekkes_gmail_com/clinical_history/training_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_path_files):\n",
    "    print('Creating output folder....')\n",
    "    os.makedirs(save_path_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_train = pd.read_excel(path_to_cleaned_training_data_xlsx), engine='openpyxl', index_col=[0])\n",
    "with open(path_to_cleaned_training_data_pkl, \"rb\") as file:\n",
    "    cleaned_train = pickle.load(file)\n",
    "display(cleaned_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_attribute_columns = ['NBB_nr','Year_Sentence_nr','Sentence']\n",
    "attributes = [col for col in cleaned_train.columns if col not in non_attribute_columns]\n",
    "print(len(attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split set-up (user input required)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'X' contains the sentences\n",
    "- 'Y' contains the attribute labels (numpy array of 1s and 0s per sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_size = 0.8\n",
    "test_size = 0.2\n",
    "print(cleaned_train[['Sentence']])\n",
    "X = cleaned_train[['Sentence']].to_numpy()\n",
    "Y = cleaned_train.loc[:,[i for i in list(cleaned_train.columns) if i not in non_attribute_columns]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative split, approach MultilabelStratifiedKFold (preferred)\n",
    "MultilabelStratifiedKFold is very suitable for creating multiple stratified folds for datasets with multiple labels. This is why we use it when training and optimizing the model later, when using the train&val dataset. Here we create the train&val dataset, and although we do not use multiple folds (we think one test set is enough), we do use the same library for continuity and ease of use. <br>\n",
    "\n",
    "We will never reach 'perfect' stratification, since a sentence can only be present in either test, or train&val, and some sentences contain multiple attributes\n",
    "\n",
    "MultilabelStratifiedKFold takes n_splits as input, and creates n_splits folds. <br>\n",
    "1/n_splits part of the data will be used as test, and the remainder for train. <br>\n",
    "e.g. for an n_splits of 5 and 10 sentences, 2 sentences function as test (==1/5), and 8 sentences as train. <br>\n",
    "This is performed 5 times, leading to 5 different 2-8 combinations. <br>\n",
    "\n",
    "Importantly, we only need a single 2-8 combination, so we exit the loop after a single run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "j = 0\n",
    "for train_val_index, test_index in mskf.split(X, Y):\n",
    "    if j == 0:\n",
    "        print(\"TRAINVAL row numbers:\", train_val_index, \"\\nTEST row numbers:\", test_index)\n",
    "        x_train_val, x_test = X[train_val_index], X[test_index]\n",
    "        y_train_val, y_test = Y[train_val_index], Y[test_index]\n",
    "        print(f\"nr of sentences in train&val: {len(x_train_val)}, or {len(x_train_val)/(len(x_train_val)+len(x_test)):.2f}%\\n\"\\\n",
    "        f\"nr of sentences in test: {len(x_test)}, or {len(x_test)/(len(x_train_val)+len(x_test)):.2f}%\")\n",
    "        print('\\nFinished splitting data once, exiting loop...')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate if attributes are distributed roughly equally between test and train&val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "std,uncor, cor = split_vis(x_train_val,x_test,y_train_val, y_test,x_train_val.shape[0],x_test.shape[0],attributes)\n",
    "print('Stratification score: ', round(std,4))\n",
    "\n",
    "print('Attribute distribution real numbers:')\n",
    "display(uncor)\n",
    "\n",
    "print('Attribute distribution numbers adjusted for sizes of train&val and test:')\n",
    "display(cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating final dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_df = pd.DataFrame(x_train_val,columns=['text'])\n",
    "trainval_df['labels'] = y_train_val.tolist()\n",
    "trainval_df.to_excel(f\"{save_path_files}/trainval_data.xlsx\")\n",
    "trainval_df.to_pickle(f\"{save_path_files}/trainval_data.pkl\") \n",
    "\n",
    "\n",
    "test_df = pd.DataFrame(x_test,columns=['text'])\n",
    "test_df['labels'] = y_test.tolist()\n",
    "test_df.to_excel(f\"{save_path_files}/test_data.xlsx\")\n",
    "test_df.to_pickle(f\"{save_path_files}/test_data.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning_env",
   "language": "python",
   "name": "machine_learning_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
